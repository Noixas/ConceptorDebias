{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Debiasing WE",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/ACL-cleanup/Debiasing_WE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nPEQDrI_IOtf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Debiasing WE with CN"
      ]
    },
    {
      "metadata": {
        "id": "o3VcosyOIVjp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set up debiasing tool"
      ]
    },
    {
      "metadata": {
        "id": "MK90107gQ3TO",
        "colab_type": "code",
        "outputId": "7c859b6e-2dbd-449d-b319-c91d1084b5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# Setup:\n",
        "# Clone the code repository from https://github.com/tolga-b/debiaswe.git\n",
        "!mkdir debiaswe_tutorial\n",
        "%cd debiaswe_tutorial\n",
        "!git clone https://github.com/tolga-b/debiaswe.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘debiaswe_tutorial’: File exists\n",
            "/content/debiaswe_tutorial\n",
            "fatal: destination path 'debiaswe' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aCT0obBvRhi_",
        "colab_type": "code",
        "outputId": "84765a2d-9a29-4112-e7db-2aff8edd66d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "cell_type": "code",
      "source": [
        "#Download word embeddings provided by the author\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.22)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NH6jcrg8SXbnhpIXRIXF_-KUE7wGxGaG\n",
            "To: /content/debiaswe_tutorial/w2v_gnews_small.zip\n",
            "29.1MB [00:00, 56.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3xPgYvymTJjX",
        "colab_type": "code",
        "outputId": "e9665f16-0085-488a-c224-b7f2cacf04d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/debiaswe_tutorial/w2v_gnews_small.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/debiaswe_tutorial/w2v_gnews_small.zip\n",
            "replace w2v_gnews_small.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: w2v_gnews_small.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bhxbm7V0JOOk",
        "colab_type": "code",
        "outputId": "e33e0408-cd9d-466a-80cd-ef186c7d14ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "jm8BGor6TCel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from debiaswe import debiaswe\n",
        "from debiaswe.debiaswe import we\n",
        "import debiaswe as dwe\n",
        "#import debiaswe.we as we\n",
        "from debiaswe.debiaswe.we import WordEmbedding\n",
        "from debiaswe.debiaswe.data import load_professions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrZPA3Kxy04s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ]
    },
    {
      "metadata": {
        "id": "IhrFIMCn1Hsc",
        "colab_type": "code",
        "outputId": "6a4913ed-b75d-4030-eff2-b5e994c834ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/debiaswe_tutorial/debiaswe"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/debiaswe_tutorial/debiaswe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_bhECvns1Gzi",
        "colab_type": "code",
        "outputId": "b56ed382-2697-4a18-ff1f-7eac754dc416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# Lets load some gender related word lists to help us with debiasing\n",
        "with open('./data/definitional_pairs.json', \"r\") as f:\n",
        "    defs = json.load(f) #gender definitional words\n",
        "print(\"definitional\", defs)\n",
        "defs_list = []\n",
        "for pair in defs:\n",
        "  defs_list.append(pair[0])\n",
        "  defs_list.append(pair[1])\n",
        "\n",
        "with open('./data/equalize_pairs.json', \"r\") as f:\n",
        "    equalize_pairs = json.load(f) \n",
        "print(equalize_pairs)\n",
        "\n",
        "with open('./data/gender_specific_seed.json', \"r\") as f:\n",
        "    gender_specific_words = json.load(f)\n",
        "print(\"gender specific\", len(gender_specific_words), gender_specific_words[:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "definitional [['woman', 'man'], ['girl', 'boy'], ['she', 'he'], ['mother', 'father'], ['daughter', 'son'], ['gal', 'guy'], ['female', 'male'], ['her', 'his'], ['herself', 'himself'], ['Mary', 'John']]\n",
            "[['monastery', 'convent'], ['spokesman', 'spokeswoman'], ['Catholic_priest', 'nun'], ['Dad', 'Mom'], ['Men', 'Women'], ['councilman', 'councilwoman'], ['grandpa', 'grandma'], ['grandsons', 'granddaughters'], ['prostate_cancer', 'ovarian_cancer'], ['testosterone', 'estrogen'], ['uncle', 'aunt'], ['wives', 'husbands'], ['Father', 'Mother'], ['Grandpa', 'Grandma'], ['He', 'She'], ['boy', 'girl'], ['boys', 'girls'], ['brother', 'sister'], ['brothers', 'sisters'], ['businessman', 'businesswoman'], ['chairman', 'chairwoman'], ['colt', 'filly'], ['congressman', 'congresswoman'], ['dad', 'mom'], ['dads', 'moms'], ['dudes', 'gals'], ['ex_girlfriend', 'ex_boyfriend'], ['father', 'mother'], ['fatherhood', 'motherhood'], ['fathers', 'mothers'], ['fella', 'granny'], ['fraternity', 'sorority'], ['gelding', 'mare'], ['gentleman', 'lady'], ['gentlemen', 'ladies'], ['grandfather', 'grandmother'], ['grandson', 'granddaughter'], ['he', 'she'], ['himself', 'herself'], ['his', 'her'], ['king', 'queen'], ['kings', 'queens'], ['male', 'female'], ['males', 'females'], ['man', 'woman'], ['men', 'women'], ['nephew', 'niece'], ['prince', 'princess'], ['schoolboy', 'schoolgirl'], ['son', 'daughter'], ['sons', 'daughters'], ['twin_brother', 'twin_sister']]\n",
            "gender specific 218 ['actress', 'actresses', 'aunt', 'aunts', 'bachelor', 'ballerina', 'barbershop', 'baritone', 'beard', 'beards']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wQM5H4Amy2oY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4yLv4YPy-S1",
        "colab_type": "code",
        "outputId": "c5464af0-187d-49a8-917d-5d76ed7e6824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m gensim.scripts.glove2word2vec -i /content/debiaswe_tutorial/w2v_gnews_small.txt -o /content/small_w2v.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2019-03-15 00:16:59,556 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py -i /content/debiaswe_tutorial/w2v_gnews_small.txt -o /content/small_w2v.txt\n",
            "2019-03-15 00:16:59,615 - glove2word2vec - INFO - converting 26423 vectors from /content/debiaswe_tutorial/w2v_gnews_small.txt to /content/small_w2v.txt\n",
            "2019-03-15 00:16:59,947 - glove2word2vec - INFO - Converted model with 26423 vectors and 300 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4c-5qtnTy-zf",
        "colab_type": "code",
        "outputId": "5cdfc5fd-9278-4517-933b-b62de967e0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#load word2vec file in a correct form\n",
        "w2v = KeyedVectors.load_word2vec_format('/content/small_w2v.txt', binary=False)\n",
        "print('The w2v embedding has been loaded!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The w2v embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vFGDaICbzGSK",
        "colab_type": "code",
        "outputId": "144bc19b-150b-41fb-df6b-3c324366746e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "from numpy.linalg import norm, inv, eig"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EgZ_i_DNzGxN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def protoConceptor(wordVecModel_str, defs_list, alpha):\n",
        "    # compute the prototype conceptor with alpha = 2\n",
        "    \n",
        "    \n",
        "    wordVecModel = eval(wordVecModel_str)    \n",
        "\n",
        "\n",
        "\n",
        "    # put the word vectors in columns\n",
        "    x_collector = wordVecModel.vectors[:].T   #total embeddings    \n",
        "        \n",
        "    num_vec = x_collector.shape[0]\n",
        "    cn_vec= []\n",
        "    for word in defs_list:\n",
        "      if word in wordVecModel.vocab:\n",
        "        cn_vec.append(wordVecModel[word])\n",
        "    cn_collector = np.transpose(cn_vec) # embeddings of gender specific words\n",
        "    nrWords = cn_collector.shape[1] # number of gender specific words\n",
        "    \n",
        "    \n",
        "    R = cn_collector.dot(cn_collector.T) / nrWords # calculate the correlation matrix\n",
        "    \n",
        "    C = R @ inv(R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    mat = ((np.eye(num_vec)-C)@ x_collector).T #transform total embeddings\n",
        "    return  mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eXLkLY-WzUMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_f_name = 'w2v'\n",
        "w2v_cn_mat = protoConceptor(cn_f_name, defs_list, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SINs3u6jzXyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#write CN word vecs into file\n",
        "model = eval('w2v')\n",
        "f = open('/content/w2v_cn.txt','w+')\n",
        "for word in model.vocab:\n",
        "  f.write(word+' ')\n",
        "  id = model.vocab[word].index\n",
        "  for item in w2v_cn_mat[id,:]:\n",
        "    f.write(str(item)+' ')\n",
        "  f.write('\\n')\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9UvfqJbPzYNI",
        "colab_type": "code",
        "outputId": "a5f38033-b38a-4c34-e23c-41838ab2e672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m gensim.scripts.glove2word2vec -i /content/w2v_cn.txt -o /content/w2v_cn_2.txt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2019-03-15 00:17:23,304 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py -i /content/w2v_cn.txt -o /content/w2v_cn_2.txt\n",
            "2019-03-15 00:17:23,436 - glove2word2vec - INFO - converting 26423 vectors from /content/w2v_cn.txt to /content/w2v_cn_2.txt\n",
            "2019-03-15 00:17:23,916 - glove2word2vec - INFO - Converted model with 26423 vectors and 300 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QH__Off6zeRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CN processed word2vec word embeddings into cn_w2v\n",
        "cn_w2v = KeyedVectors.load_word2vec_format('/content/w2v_cn_2.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qmFXq4bATCV-",
        "colab_type": "code",
        "outputId": "a114a26e-578d-461c-a228-58336cad92d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "# load professions words\n",
        "professions = load_professions()\n",
        "profession_words = [p[0] for p in professions]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded professions\n",
            "Format:\n",
            "word,\n",
            "definitional female -1.0 -> definitional male 1.0\n",
            "stereotypical female -1.0 -> stereotypical male 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bcBRS7N1rFwE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Raw data results on gender direction using profession words\n",
        "Top 20 neighbors are shown"
      ]
    },
    {
      "metadata": {
        "id": "dtgQF_rwUNC7",
        "colab_type": "code",
        "outputId": "133b0b96-c81d-477b-9fb2-bc45c98d6668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# load google news word2vec\n",
        "E = WordEmbedding('/content/debiaswe_tutorial/w2v_gnews_small.txt')\n",
        "# gender direction\n",
        "v_gender = E.diff('she', 'he')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Reading data from /content/debiaswe_tutorial/w2v_gnews_small.txt\n",
            "(26423, 300)\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BIlSiuinbQE9",
        "colab_type": "code",
        "outputId": "9754c1a8-c602-4f30-b0db-d5180c3f7a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "#sp projected words onto he-she axis and sorted neighbors based on distance\n",
        "sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words])\n",
        "\n",
        "#Top 20 neigbors of he and top 20 neighbors of she, and their distances to he/she\n",
        "sp[0:20],sp[-20:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.23798442, 'maestro'),\n",
              "  (-0.21665451, 'statesman'),\n",
              "  (-0.20758669, 'skipper'),\n",
              "  (-0.20267202, 'protege'),\n",
              "  (-0.2020676, 'businessman'),\n",
              "  (-0.19492392, 'sportsman'),\n",
              "  (-0.18836352, 'philosopher'),\n",
              "  (-0.1807366, 'marksman'),\n",
              "  (-0.1728986, 'captain'),\n",
              "  (-0.16785555, 'architect'),\n",
              "  (-0.16702037, 'financier'),\n",
              "  (-0.16313636, 'warrior'),\n",
              "  (-0.15280862, 'major_leaguer'),\n",
              "  (-0.15001445, 'trumpeter'),\n",
              "  (-0.14718868, 'broadcaster'),\n",
              "  (-0.14637242, 'magician'),\n",
              "  (-0.14401694, 'fighter_pilot'),\n",
              "  (-0.13782285, 'boss'),\n",
              "  (-0.137182, 'industrialist'),\n",
              "  (-0.13684885, 'pundit')],\n",
              " [(0.19714224, 'interior_designer'),\n",
              "  (0.20833439, 'housekeeper'),\n",
              "  (0.21560375, 'stylist'),\n",
              "  (0.2236317, 'bookkeeper'),\n",
              "  (0.23776126, 'maid'),\n",
              "  (0.24125955, 'nun'),\n",
              "  (0.24782579, 'nanny'),\n",
              "  (0.24929334, 'hairdresser'),\n",
              "  (0.24946158, 'paralegal'),\n",
              "  (0.25276464, 'ballerina'),\n",
              "  (0.25718823, 'socialite'),\n",
              "  (0.26647124, 'librarian'),\n",
              "  (0.27317622, 'receptionist'),\n",
              "  (0.27540293, 'waitress'),\n",
              "  (0.28085968, 'nurse'),\n",
              "  (0.3042623, 'registered_nurse'),\n",
              "  (0.3043797, 'homemaker'),\n",
              "  (0.3403659, 'housewife'),\n",
              "  (0.3523514, 'actress'),\n",
              "  (0.35965404, 'businesswoman')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "esFto6fyrvd_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CN data results on gender direction using profession words"
      ]
    },
    {
      "metadata": {
        "id": "5veg30-gUTvm",
        "colab_type": "code",
        "outputId": "b031e566-f539-4ffe-8cf2-f8f2431ce870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Load CN word embeddings\n",
        "E_cn = WordEmbedding('/content/w2v_cn.txt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Reading data from /content/w2v_cn.txt\n",
            "(26423, 300)\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5zI8SxhnUuVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v_gender_cn = E_cn.diff('she', 'he')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PngLgRTHUzvp",
        "colab_type": "code",
        "outputId": "a9067d63-43a5-4f51-83d8-fc256072acd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "# Top 20 neighbors after CN\n",
        "sp = sorted([(E_cn.v(w).dot(v_gender_cn), w) for w in profession_words])\n",
        "\n",
        "sp[0:20], sp[-20:]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.19818926, 'maestro'),\n",
              "  (-0.18967961, 'statesman'),\n",
              "  (-0.1880296, 'businessman'),\n",
              "  (-0.18281998, 'skipper'),\n",
              "  (-0.18042295, 'protege'),\n",
              "  (-0.17646421, 'sportsman'),\n",
              "  (-0.16928828, 'captain'),\n",
              "  (-0.16235389, 'warrior'),\n",
              "  (-0.16157728, 'philosopher'),\n",
              "  (-0.15046968, 'marksman'),\n",
              "  (-0.13698363, 'major_leaguer'),\n",
              "  (-0.1355408, 'fighter_pilot'),\n",
              "  (-0.132551, 'financier'),\n",
              "  (-0.13202478, 'lieutenant'),\n",
              "  (-0.13006216, 'trumpeter'),\n",
              "  (-0.13000073, 'industrialist'),\n",
              "  (-0.12769677, 'architect'),\n",
              "  (-0.12576684, 'broadcaster'),\n",
              "  (-0.122493416, 'mechanic'),\n",
              "  (-0.12220184, 'magician')],\n",
              " [(0.1333736, 'housekeeper'),\n",
              "  (0.13594729, 'maid'),\n",
              "  (0.14111671, 'interior_designer'),\n",
              "  (0.15676282, 'nun'),\n",
              "  (0.16862068, 'stylist'),\n",
              "  (0.17241657, 'ballerina'),\n",
              "  (0.17548509, 'socialite'),\n",
              "  (0.17573729, 'nanny'),\n",
              "  (0.1771008, 'nurse'),\n",
              "  (0.18136254, 'bookkeeper'),\n",
              "  (0.18577197, 'librarian'),\n",
              "  (0.19130343, 'waitress'),\n",
              "  (0.19306836, 'paralegal'),\n",
              "  (0.1936686, 'hairdresser'),\n",
              "  (0.19837798, 'receptionist'),\n",
              "  (0.21897542, 'homemaker'),\n",
              "  (0.22392696, 'registered_nurse'),\n",
              "  (0.23752208, 'housewife'),\n",
              "  (0.25552708, 'actress'),\n",
              "  (0.26735374, 'businesswoman')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "GeNOtHVYwgA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Indirect Bias results using raw and CN\n",
        "After CN negation, words on softball-football axis became less gender biased."
      ]
    },
    {
      "metadata": {
        "id": "SeNG1vUYccla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v_gender = E.diff('softball', 'football')\n",
        "v_gender_cn = E_cn.diff('softball', 'football')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eM1l4Ql7sGU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Raw data results"
      ]
    },
    {
      "metadata": {
        "id": "xwe3xfijcik9",
        "colab_type": "code",
        "outputId": "2ce705ee-1e5a-4617-daec-16e3519a7e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words])\n",
        "\n",
        "sp[0:20], sp[-20:]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.3378573, 'footballer'),\n",
              "  (-0.19598085, 'businessman'),\n",
              "  (-0.19320746, 'pundit'),\n",
              "  (-0.18045807, 'maestro'),\n",
              "  (-0.16597804, 'cleric'),\n",
              "  (-0.16489363, 'marksman'),\n",
              "  (-0.1635845, 'hitman'),\n",
              "  (-0.16318859, 'philosopher'),\n",
              "  (-0.15652362, 'statesman'),\n",
              "  (-0.15603065, 'sportsman'),\n",
              "  (-0.15583786, 'broadcaster'),\n",
              "  (-0.1511248, 'banker'),\n",
              "  (-0.1446815, 'boss'),\n",
              "  (-0.14366435, 'gangster'),\n",
              "  (-0.14306568, 'midfielder'),\n",
              "  (-0.13627477, 'financier'),\n",
              "  (-0.13474312, 'policeman'),\n",
              "  (-0.13387913, 'cameraman'),\n",
              "  (-0.1336779, 'vice_chancellor'),\n",
              "  (-0.13013485, 'architect')],\n",
              " [(0.07963051, 'stylist'),\n",
              "  (0.080893494, 'housekeeper'),\n",
              "  (0.0827892, 'actress'),\n",
              "  (0.08613199, 'treasurer'),\n",
              "  (0.08741376, 'businesswoman'),\n",
              "  (0.088028535, 'counselor'),\n",
              "  (0.09069986, 'librarian'),\n",
              "  (0.09132401, 'nanny'),\n",
              "  (0.09736764, 'publicist'),\n",
              "  (0.100761496, 'therapist'),\n",
              "  (0.101995654, 'soloist'),\n",
              "  (0.114671476, 'infielder'),\n",
              "  (0.116350956, 'valedictorian'),\n",
              "  (0.13610226, 'clerk'),\n",
              "  (0.13884133, 'homemaker'),\n",
              "  (0.14254922, 'paralegal'),\n",
              "  (0.14510404, 'waitress'),\n",
              "  (0.15662505, 'registered_nurse'),\n",
              "  (0.15878208, 'receptionist'),\n",
              "  (0.17852843, 'bookkeeper')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "vRaThy74sJ_U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CN results"
      ]
    },
    {
      "metadata": {
        "id": "xOLNR31Fc9cm",
        "colab_type": "code",
        "outputId": "56d1f86d-51ae-499e-f911-e55904125e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "sp = sorted([(E_cn.v(w).dot(v_gender_cn), w) for w in profession_words])\n",
        "\n",
        "sp[0:20], sp[-20:]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.34442955, 'footballer'),\n",
              "  (-0.17447214, 'pundit'),\n",
              "  (-0.16029751, 'cleric'),\n",
              "  (-0.15683536, 'businessman'),\n",
              "  (-0.14433442, 'midfielder'),\n",
              "  (-0.14430456, 'hitman'),\n",
              "  (-0.14382309, 'vice_chancellor'),\n",
              "  (-0.1408222, 'banker'),\n",
              "  (-0.1355176, 'maestro'),\n",
              "  (-0.13379517, 'broadcaster'),\n",
              "  (-0.13157055, 'lecturer'),\n",
              "  (-0.13030419, 'marksman'),\n",
              "  (-0.12713684, 'philosopher'),\n",
              "  (-0.11896048, 'boss'),\n",
              "  (-0.11675761, 'sportsman'),\n",
              "  (-0.11546311, 'statesman'),\n",
              "  (-0.11324482, 'gangster'),\n",
              "  (-0.11297941, 'firebrand'),\n",
              "  (-0.11291969, 'cameraman'),\n",
              "  (-0.112491034, 'policeman')],\n",
              " [(0.07075992, 'attorney'),\n",
              "  (0.07231749, 'nanny'),\n",
              "  (0.07735392, 'patrolman'),\n",
              "  (0.07913429, 'major_leaguer'),\n",
              "  (0.079291396, 'counselor'),\n",
              "  (0.08319657, 'treasurer'),\n",
              "  (0.08672979, 'publicist'),\n",
              "  (0.08748335, 'trooper'),\n",
              "  (0.08990188, 'therapist'),\n",
              "  (0.089979075, 'investigator'),\n",
              "  (0.09167763, 'soloist'),\n",
              "  (0.10601995, 'homemaker'),\n",
              "  (0.11213362, 'valedictorian'),\n",
              "  (0.1140725, 'paralegal'),\n",
              "  (0.11892958, 'registered_nurse'),\n",
              "  (0.12718394, 'waitress'),\n",
              "  (0.13183203, 'receptionist'),\n",
              "  (0.13311936, 'clerk'),\n",
              "  (0.13943228, 'infielder'),\n",
              "  (0.16408974, 'bookkeeper')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "fYVRmHI1v0WO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hard Debiasing\n",
        "Perform hard debiasing on word embeddings and save hard-debiased embeddings into debiased.txt file."
      ]
    },
    {
      "metadata": {
        "id": "JL4dJKzdVhsu",
        "colab_type": "code",
        "outputId": "95dd711e-1412-4016-c8df-3b02bf662859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/debiaswe_tutorial/debiaswe/debiaswe/"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/debiaswe_tutorial/debiaswe/debiaswe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lbjorfdRU1IY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from debiaswe.debiaswe import debias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtklgycYWjJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from debiaswe.debiaswe.debias import debias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8l8kJwg2Vqs1",
        "colab_type": "code",
        "outputId": "e987893a-0f3e-4bc2-fdc1-4da01943a3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/debiaswe_tutorial/debiaswe"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/debiaswe_tutorial/debiaswe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foC_Mh3vUI2m",
        "colab_type": "code",
        "outputId": "aeae8273-0776-4778-fe78-96756b5acda4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "E = WordEmbedding('/content/debiaswe_tutorial/w2v_gnews_small.txt')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Reading data from /content/debiaswe_tutorial/w2v_gnews_small.txt\n",
            "(26423, 300)\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GdyK1yK3WA68",
        "colab_type": "code",
        "outputId": "ed68511c-02d1-44be-efbe-ec9aa541949b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "#Using authos's debiasing function\n",
        "debias(E, gender_specific_words, defs, equalize_pairs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n",
            "{('Fathers', 'Mothers'), ('Grandpa', 'Grandma'), ('KING', 'QUEEN'), ('fella', 'granny'), ('males', 'females'), ('Brother', 'Sister'), ('Prince', 'Princess'), ('Fatherhood', 'Motherhood'), ('gelding', 'mare'), ('GRANDSONS', 'GRANDDAUGHTERS'), ('monastery', 'convent'), ('Men', 'Women'), ('male', 'female'), ('Dudes', 'Gals'), ('King', 'Queen'), ('Boy', 'Girl'), ('son', 'daughter'), ('Twin_Brother', 'Twin_Sister'), ('COLT', 'FILLY'), ('Gentleman', 'Lady'), ('MAN', 'WOMAN'), ('NEPHEW', 'NIECE'), ('congressman', 'congresswoman'), ('MONASTERY', 'CONVENT'), ('CATHOLIC_PRIEST', 'NUN'), ('Spokesman', 'Spokeswoman'), ('MALES', 'FEMALES'), ('Dad', 'Mom'), ('twin_brother', 'twin_sister'), ('gentleman', 'lady'), ('Grandsons', 'Granddaughters'), ('nephew', 'niece'), ('Fraternity', 'Sorority'), ('Gelding', 'Mare'), ('KINGS', 'QUEENS'), ('COUNCILMAN', 'COUNCILWOMAN'), ('councilman', 'councilwoman'), ('dudes', 'gals'), ('schoolboy', 'schoolgirl'), ('Father', 'Mother'), ('boy', 'girl'), ('Businessman', 'Businesswoman'), ('Fella', 'Granny'), ('GRANDSON', 'GRANDDAUGHTER'), ('TESTOSTERONE', 'ESTROGEN'), ('brother', 'sister'), ('chairman', 'chairwoman'), ('SON', 'DAUGHTER'), ('CHAIRMAN', 'CHAIRWOMAN'), ('Councilman', 'Councilwoman'), ('WIVES', 'HUSBANDS'), ('fraternity', 'sorority'), ('Grandson', 'Granddaughter'), ('FATHER', 'MOTHER'), ('men', 'women'), ('BROTHERS', 'SISTERS'), ('spokesman', 'spokeswoman'), ('DUDES', 'GALS'), ('UNCLE', 'AUNT'), ('CONGRESSMAN', 'CONGRESSWOMAN'), ('Testosterone', 'Estrogen'), ('kings', 'queens'), ('Monastery', 'Convent'), ('Males', 'Females'), ('grandfather', 'grandmother'), ('EX_GIRLFRIEND', 'EX_BOYFRIEND'), ('DAD', 'MOM'), ('testosterone', 'estrogen'), ('colt', 'filly'), ('wives', 'husbands'), ('His', 'Her'), ('Wives', 'Husbands'), ('Kings', 'Queens'), ('TWIN_BROTHER', 'TWIN_SISTER'), ('BOY', 'GIRL'), ('SCHOOLBOY', 'SCHOOLGIRL'), ('Gentlemen', 'Ladies'), ('SONS', 'DAUGHTERS'), ('man', 'woman'), ('grandson', 'granddaughter'), ('Sons', 'Daughters'), ('FELLA', 'GRANNY'), ('BOYS', 'GIRLS'), ('GRANDFATHER', 'GRANDMOTHER'), ('GENTLEMEN', 'LADIES'), ('BROTHER', 'SISTER'), ('GRANDPA', 'GRANDMA'), ('Brothers', 'Sisters'), ('dads', 'moms'), ('Himself', 'Herself'), ('Dads', 'Moms'), ('gentlemen', 'ladies'), ('grandpa', 'grandma'), ('DADS', 'MOMS'), ('BUSINESSMAN', 'BUSINESSWOMAN'), ('Ex_Girlfriend', 'Ex_Boyfriend'), ('Congressman', 'Congresswoman'), ('Schoolboy', 'Schoolgirl'), ('Catholic_Priest', 'Nun'), ('king', 'queen'), ('HE', 'SHE'), ('PROSTATE_CANCER', 'OVARIAN_CANCER'), ('Male', 'Female'), ('grandsons', 'granddaughters'), ('fatherhood', 'motherhood'), ('Grandfather', 'Grandmother'), ('father', 'mother'), ('fathers', 'mothers'), ('GENTLEMAN', 'LADY'), ('catholic_priest', 'nun'), ('Son', 'Daughter'), ('sons', 'daughters'), ('himself', 'herself'), ('uncle', 'aunt'), ('Nephew', 'Niece'), ('boys', 'girls'), ('Man', 'Woman'), ('PRINCE', 'PRINCESS'), ('brothers', 'sisters'), ('Uncle', 'Aunt'), ('dad', 'mom'), ('prostate_cancer', 'ovarian_cancer'), ('MEN', 'WOMEN'), ('Colt', 'Filly'), ('HIS', 'HER'), ('Prostate_Cancer', 'Ovarian_Cancer'), ('ex_girlfriend', 'ex_boyfriend'), ('He', 'She'), ('HIMSELF', 'HERSELF'), ('FATHERHOOD', 'MOTHERHOOD'), ('businessman', 'businesswoman'), ('FRATERNITY', 'SORORITY'), ('he', 'she'), ('FATHERS', 'MOTHERS'), ('GELDING', 'MARE'), ('Chairman', 'Chairwoman'), ('MALE', 'FEMALE'), ('prince', 'princess'), ('SPOKESMAN', 'SPOKESWOMAN'), ('Boys', 'Girls'), ('his', 'her')}\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rMNFGKm6xnJ8",
        "colab_type": "code",
        "outputId": "bb0ff3fa-7c26-4079-9248-29cc8bdb3f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9gCRcpo0Xkse",
        "colab_type": "code",
        "outputId": "f0cf1eeb-5dfc-4d67-fc5c-ffe0f10b91b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Save debiased word embeddings\n",
        "E.save('debiased.txt')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote 26423 words to debiased.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lvo4Uk62Xwn7",
        "colab_type": "code",
        "outputId": "d266cf63-0fa9-4ac4-a6a9-5f00d15b74a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "E_de = WordEmbedding('/content/debiased.txt')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Reading data from /content/debiased.txt\n",
            "(26423, 300)\n",
            "26423 words of dimension 300 : in, for, that, is, ..., Jay, Leroy, Brad, Jermaine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GQULin-byUgN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Direct Bias Results(Hard Debiasing) -- Gender\n",
        "hard debiasing results on gender direction using profession words"
      ]
    },
    {
      "metadata": {
        "id": "KtCMMjOzoBBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v_gender_de =E_de.diff('she', 'he')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "or3EKOEiXCBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "2f14f348-7c44-4567-a135-e59157b674ee"
      },
      "cell_type": "code",
      "source": [
        "# profession analysis gender\n",
        "sp_debiased = sorted([(E_de.v(w).dot(v_gender_de), w) for w in profession_words])\n",
        "\n",
        "sp_debiased[0:20], sp_debiased[-20:]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.43325222, 'businessman'),\n",
              "  (-0.42799947, 'congressman'),\n",
              "  (-0.36525276, 'dad'),\n",
              "  (-0.35791722, 'councilman'),\n",
              "  (-0.22225758, 'statesman'),\n",
              "  (-0.15711337, 'salesman'),\n",
              "  (-0.106753685, 'handyman'),\n",
              "  (-0.08172015, 'monk'),\n",
              "  (-3.8995495e-08, 'soldier'),\n",
              "  (-3.7778136e-08, 'policeman'),\n",
              "  (-3.5121047e-08, 'teenager'),\n",
              "  (-3.421883e-08, 'drug_addict'),\n",
              "  (-3.4161076e-08, 'politician'),\n",
              "  (-3.3038305e-08, 'confesses'),\n",
              "  (-3.2116077e-08, 'swimmer'),\n",
              "  (-3.1512172e-08, 'prisoner'),\n",
              "  (-3.1272066e-08, 'aide'),\n",
              "  (-3.1170202e-08, 'senator'),\n",
              "  (-3.0962838e-08, 'athlete'),\n",
              "  (-3.0879164e-08, 'parliamentarian')],\n",
              " [(-8.0035534e-11, 'artiste'),\n",
              "  (-7.2759576e-11, 'pundit'),\n",
              "  (2.6921043e-10, 'researcher'),\n",
              "  (5.7480065e-10, 'undersecretary'),\n",
              "  (6.1118044e-10, 'tycoon'),\n",
              "  (1.0772965e-09, 'author'),\n",
              "  (1.4551915e-09, 'dermatologist'),\n",
              "  (1.4842954e-09, 'interior_designer'),\n",
              "  (1.5188562e-09, 'saxophonist'),\n",
              "  (3.8307917e-09, 'illustrator'),\n",
              "  (4.4237822e-09, 'associate_professor'),\n",
              "  (4.5929482e-09, 'archaeologist'),\n",
              "  (9.240466e-09, 'restaurateur'),\n",
              "  (0.2606187, 'ballerina'),\n",
              "  (0.26477975, 'nun'),\n",
              "  (0.27208695, 'maid'),\n",
              "  (0.2965596, 'waitress'),\n",
              "  (0.3784349, 'housewife'),\n",
              "  (0.3788142, 'actress'),\n",
              "  (0.43325216, 'businesswoman')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "M2RFY6OoyZL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Indirect Bias(Hard Debiasing)\n",
        "hard debiasing results on non-gendered direction using profession words"
      ]
    },
    {
      "metadata": {
        "id": "aqvax-SqXHuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v_gender_de =E_de.diff('softball', 'football')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sR-hnPVfx5oD",
        "colab_type": "code",
        "outputId": "3e6af0b3-70fd-4cdf-f6ba-5d3a5b57e16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "sp_debiased = sorted([(E_de.v(w).dot(v_gender_de), w) for w in profession_words])\n",
        "\n",
        "sp_debiased[0:20], sp_debiased[-20:]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(-0.32501778, 'footballer'),\n",
              "  (-0.16693358, 'cleric'),\n",
              "  (-0.15964463, 'vice_chancellor'),\n",
              "  (-0.15362918, 'lecturer'),\n",
              "  (-0.1531749, 'midfielder'),\n",
              "  (-0.1515184, 'fashion_designer'),\n",
              "  (-0.14984937, 'housewife'),\n",
              "  (-0.14895485, 'pundit'),\n",
              "  (-0.13962688, 'student'),\n",
              "  (-0.13837737, 'banker'),\n",
              "  (-0.12876885, 'hitman'),\n",
              "  (-0.126078, 'civil_servant'),\n",
              "  (-0.12569053, 'chancellor'),\n",
              "  (-0.124440275, 'socialite'),\n",
              "  (-0.121996544, 'journalist'),\n",
              "  (-0.11445205, 'artiste'),\n",
              "  (-0.11225906, 'entertainer'),\n",
              "  (-0.1106455, 'broadcaster'),\n",
              "  (-0.11030317, 'serviceman'),\n",
              "  (-0.10903629, 'filmmaker')],\n",
              " [(0.046729255, 'deputy'),\n",
              "  (0.048755586, 'geologist'),\n",
              "  (0.049729493, 'paralegal'),\n",
              "  (0.050405726, 'councilman'),\n",
              "  (0.05245539, 'lifeguard'),\n",
              "  (0.05282015, 'organist'),\n",
              "  (0.055579696, 'assassin'),\n",
              "  (0.058301304, 'instructor'),\n",
              "  (0.060144324, 'soloist'),\n",
              "  (0.064725064, 'attorney'),\n",
              "  (0.06975241, 'foreman'),\n",
              "  (0.07452034, 'treasurer'),\n",
              "  (0.07646255, 'trooper'),\n",
              "  (0.0775902, 'valedictorian'),\n",
              "  (0.07845981, 'clerk'),\n",
              "  (0.081745565, 'investigator'),\n",
              "  (0.09263827, 'patrolman'),\n",
              "  (0.104208596, 'bookkeeper'),\n",
              "  (0.113699816, 'major_leaguer'),\n",
              "  (0.14989373, 'infielder')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "qPQEI6QxYiAy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compare CN, hard-debiasing and raw results on word-similarity tasks"
      ]
    },
    {
      "metadata": {
        "id": "mFlO7_JnYhQ6",
        "colab_type": "code",
        "outputId": "8f2e8e95-8b37-4d2b-c3df-34c8358abda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zsHx1JJjY9Gc",
        "colab_type": "code",
        "outputId": "dca1f2b4-4d94-45b8-9523-c3eea93eb4f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1492
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-MEN-TR-3k.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-MTurk-287.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-RG-65.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-RW-STANFORD.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-SIMLEX-999.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-SimVerb-3500.txt\n",
        "!wget https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-WS-353-ALL.txt\n",
        "!ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-15 00:17:53--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-MEN-TR-3k.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53593 (52K) [text/plain]\n",
            "Saving to: ‘EN-MEN-TR-3k.txt.1’\n",
            "\n",
            "\rEN-MEN-TR-3k.txt.1    0%[                    ]       0  --.-KB/s               \rEN-MEN-TR-3k.txt.1  100%[===================>]  52.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-15 00:17:54 (2.17 MB/s) - ‘EN-MEN-TR-3k.txt.1’ saved [53593/53593]\n",
            "\n",
            "--2019-03-15 00:17:54--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-MTurk-287.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7218 (7.0K) [text/plain]\n",
            "Saving to: ‘EN-MTurk-287.txt.1’\n",
            "\n",
            "EN-MTurk-287.txt.1  100%[===================>]   7.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-15 00:17:55 (92.7 MB/s) - ‘EN-MTurk-287.txt.1’ saved [7218/7218]\n",
            "\n",
            "--2019-03-15 00:17:55--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-RG-65.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1210 (1.2K) [text/plain]\n",
            "Saving to: ‘EN-RG-65.txt.1’\n",
            "\n",
            "EN-RG-65.txt.1      100%[===================>]   1.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-15 00:17:56 (169 MB/s) - ‘EN-RG-65.txt.1’ saved [1210/1210]\n",
            "\n",
            "--2019-03-15 00:17:56--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-RW-STANFORD.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49851 (49K) [text/plain]\n",
            "Saving to: ‘EN-RW-STANFORD.txt.1’\n",
            "\n",
            "EN-RW-STANFORD.txt. 100%[===================>]  48.68K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-15 00:17:56 (1.95 MB/s) - ‘EN-RW-STANFORD.txt.1’ saved [49851/49851]\n",
            "\n",
            "--2019-03-15 00:17:57--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-SIMLEX-999.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18024 (18K) [text/plain]\n",
            "Saving to: ‘EN-SIMLEX-999.txt.1’\n",
            "\n",
            "EN-SIMLEX-999.txt.1 100%[===================>]  17.60K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-03-15 00:17:57 (1.43 MB/s) - ‘EN-SIMLEX-999.txt.1’ saved [18024/18024]\n",
            "\n",
            "--2019-03-15 00:17:58--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-SimVerb-3500.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65315 (64K) [text/plain]\n",
            "Saving to: ‘EN-SimVerb-3500.txt.1’\n",
            "\n",
            "EN-SimVerb-3500.txt 100%[===================>]  63.78K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-15 00:17:58 (2.70 MB/s) - ‘EN-SimVerb-3500.txt.1’ saved [65315/65315]\n",
            "\n",
            "--2019-03-15 00:17:59--  https://raw.githubusercontent.com/liutianlin0121/Conceptor-Negation-WV/master/data/wordSimData/EN-WS-353-ALL.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7405 (7.2K) [text/plain]\n",
            "Saving to: ‘EN-WS-353-ALL.txt.1’\n",
            "\n",
            "EN-WS-353-ALL.txt.1 100%[===================>]   7.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-15 00:17:59 (94.4 MB/s) - ‘EN-WS-353-ALL.txt.1’ saved [7405/7405]\n",
            "\n",
            "debiased.txt\t    EN-MTurk-287.txt.1\t  EN-SIMLEX-999.txt.1\t small_w2v.txt\n",
            "debiased_w2v.txt    EN-RG-65.txt\t  EN-SimVerb-3500.txt\t w2v_cn_2.txt\n",
            "debiaswe_tutorial   EN-RG-65.txt.1\t  EN-SimVerb-3500.txt.1  w2v_cn.txt\n",
            "EN-MEN-TR-3k.txt    EN-RW-STANFORD.txt\t  EN-WS-353-ALL.txt\n",
            "EN-MEN-TR-3k.txt.1  EN-RW-STANFORD.txt.1  EN-WS-353-ALL.txt.1\n",
            "EN-MTurk-287.txt    EN-SIMLEX-999.txt\t  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z9OmAg71ZCmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sim_no_cn(data_f_name, f_name):\n",
        "  model = eval(f_name)\n",
        "  fin = io.open(data_f_name, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "  data = []\n",
        "  line_num = 0\n",
        "  for line in fin:\n",
        "      tokens = line.rstrip().split()\n",
        "      if tokens[0] in model.vocab and tokens[1] in model.vocab:\n",
        "        data.append(((tokens[0], tokens[1]), float(tokens[2])))\n",
        " \n",
        "  data.sort(key = lambda score: -score[1]) #sort based on score\n",
        "  dataset = {}\n",
        "  dataset_list = []\n",
        "  \n",
        "  for ((word1, word2), score) in data:\n",
        "    sim_score = 1 - cosine_similarity(model[word1].reshape(1,-1), model[word2].reshape(1,-1))\n",
        "    dataset[(word1, word2)] = sim_score\n",
        "    dataset_list.append(((word1, word2),sim_score))\n",
        "  dataset_list.sort(key = lambda score: score[1])\n",
        "  spearman_list1=[]\n",
        "  spearman_list2=[]\n",
        "  for pos_1, (pair, score_1) in enumerate(data):\n",
        "    score_2 = dataset[pair]\n",
        "    pos_2 = dataset_list.index((pair, score_2))\n",
        "    spearman_list1.append(pos_1)\n",
        "    spearman_list2.append(pos_2)\n",
        "  rho = spearmanr(spearman_list1, spearman_list2)\n",
        "  return rho[0] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5tGb0rqzxSI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is a slight difference between the results below and the results in paper. The reason is that the author said that their word embeddings dataset has 26377 words, but the dataset they provided on github has 26423 words. I tried data cleaning methods discussed in their paper but still got 26423 words. The difference in entries would cause the difference. \n",
        "\n",
        "In their paper, they only used EN-RG-65 and EN-WS-353."
      ]
    },
    {
      "metadata": {
        "id": "cY5yoDsPsYYt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Raw data"
      ]
    },
    {
      "metadata": {
        "id": "Xz5QgIICZOmB",
        "colab_type": "code",
        "outputId": "b66d6355-2aa6-4653-b44a-ebc155db2d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "dataSets = ['EN-RG-65.txt', 'EN-WS-353-ALL.txt', 'EN-RW-STANFORD.txt', 'EN-MEN-TR-3k.txt', 'EN-MTurk-287.txt', 'EN-SIMLEX-999.txt', 'EN-SimVerb-3500.txt']\n",
        "for dataset in dataSets:\n",
        "    dataSetAddress = '/content/'+  dataset\n",
        "    print('evaluating the data set', dataSetAddress)\n",
        "    print('w2v ')\n",
        "    print(\"%.4f\" % get_sim_no_cn(dataSetAddress, 'w2v'))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluating the data set /content/EN-RG-65.txt\n",
            "w2v \n",
            "0.7621\n",
            "evaluating the data set /content/EN-WS-353-ALL.txt\n",
            "w2v \n",
            "0.6880\n",
            "evaluating the data set /content/EN-RW-STANFORD.txt\n",
            "w2v \n",
            "0.6542\n",
            "evaluating the data set /content/EN-MEN-TR-3k.txt\n",
            "w2v \n",
            "0.7742\n",
            "evaluating the data set /content/EN-MTurk-287.txt\n",
            "w2v \n",
            "0.6958\n",
            "evaluating the data set /content/EN-SIMLEX-999.txt\n",
            "w2v \n",
            "0.4448\n",
            "evaluating the data set /content/EN-SimVerb-3500.txt\n",
            "w2v \n",
            "0.3562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g_Vu9sh2af3M",
        "colab_type": "code",
        "outputId": "d30f226b-c58c-4759-dd1f-0844c4f14946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m gensim.scripts.glove2word2vec -i /content/debiased.txt -o /content/debiased_w2v.txt"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2019-03-15 00:18:04,578 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py -i /content/debiased.txt -o /content/debiased_w2v.txt\n",
            "2019-03-15 00:18:04,653 - glove2word2vec - INFO - converting 26423 vectors from /content/debiased.txt to /content/debiased_w2v.txt\n",
            "2019-03-15 00:18:04,909 - glove2word2vec - INFO - Converted model with 26423 vectors and 300 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "knfx9s-PpYxF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hard-debiasing"
      ]
    },
    {
      "metadata": {
        "id": "Tnu52_9UbEeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w2v_de = KeyedVectors.load_word2vec_format('/content/debiased_w2v.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sW5n_vmbNWr",
        "colab_type": "code",
        "outputId": "74929d14-a710-4e24-a1b2-3fa65c54efdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "dataSets = ['EN-RG-65.txt', 'EN-WS-353-ALL.txt', 'EN-RW-STANFORD.txt', 'EN-MEN-TR-3k.txt', 'EN-MTurk-287.txt', 'EN-SIMLEX-999.txt', 'EN-SimVerb-3500.txt']\n",
        "for dataset in dataSets:\n",
        "    dataSetAddress = '/content/'+  dataset\n",
        "    print('evaluating the data set', dataSetAddress)\n",
        "    print('w2v ')\n",
        "    print(\"%.4f\" % get_sim_no_cn(dataSetAddress, 'w2v_de'))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluating the data set /content/EN-RG-65.txt\n",
            "w2v \n",
            "0.7604\n",
            "evaluating the data set /content/EN-WS-353-ALL.txt\n",
            "w2v \n",
            "0.6850\n",
            "evaluating the data set /content/EN-RW-STANFORD.txt\n",
            "w2v \n",
            "0.6544\n",
            "evaluating the data set /content/EN-MEN-TR-3k.txt\n",
            "w2v \n",
            "0.7730\n",
            "evaluating the data set /content/EN-MTurk-287.txt\n",
            "w2v \n",
            "0.6957\n",
            "evaluating the data set /content/EN-SIMLEX-999.txt\n",
            "w2v \n",
            "0.4474\n",
            "evaluating the data set /content/EN-SimVerb-3500.txt\n",
            "w2v \n",
            "0.3562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bjgyj6Q9ILU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CN results"
      ]
    },
    {
      "metadata": {
        "id": "Xtwx9EcDM2DT",
        "colab_type": "code",
        "outputId": "d652bd86-e189-4308-f94a-a2095f1ecc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "dataSets = ['EN-RG-65.txt', 'EN-WS-353-ALL.txt', 'EN-RW-STANFORD.txt', 'EN-MEN-TR-3k.txt', 'EN-MTurk-287.txt', 'EN-SIMLEX-999.txt', 'EN-SimVerb-3500.txt']\n",
        "for dataset in dataSets:\n",
        "    dataSetAddress = '/content/'+  dataset\n",
        "    print('evaluating the data set', dataSetAddress)\n",
        "    print('w2v ')\n",
        "    print(\"%.4f\" % get_sim_no_cn(dataSetAddress, 'cn_w2v'))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluating the data set /content/EN-RG-65.txt\n",
            "w2v \n",
            "0.7628\n",
            "evaluating the data set /content/EN-WS-353-ALL.txt\n",
            "w2v \n",
            "0.6886\n",
            "evaluating the data set /content/EN-RW-STANFORD.txt\n",
            "w2v \n",
            "0.6568\n",
            "evaluating the data set /content/EN-MEN-TR-3k.txt\n",
            "w2v \n",
            "0.7765\n",
            "evaluating the data set /content/EN-MTurk-287.txt\n",
            "w2v \n",
            "0.6889\n",
            "evaluating the data set /content/EN-SIMLEX-999.txt\n",
            "w2v \n",
            "0.4584\n",
            "evaluating the data set /content/EN-SimVerb-3500.txt\n",
            "w2v \n",
            "0.3625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}