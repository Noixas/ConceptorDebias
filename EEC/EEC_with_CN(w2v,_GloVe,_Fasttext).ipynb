{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEC with CN(w2v, GloVe, Fasttext)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/ACL-cleanup/EEC_with_CN(w2v%2C_GloVe%2C_Fasttext).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Pz4EMOLUOuCL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load EEC"
      ]
    },
    {
      "metadata": {
        "id": "WQJS8yEwygVb",
        "colab_type": "code",
        "outputId": "115be578-1c2e-447c-deae-904b1502abf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-15 01:33:19--  http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip\n",
            "Resolving www.saifmohammad.com (www.saifmohammad.com)... 192.185.17.122\n",
            "Connecting to www.saifmohammad.com (www.saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102568 (100K) [application/zip]\n",
            "Saving to: ‘Equity-Evaluation-Corpus.zip.1’\n",
            "\n",
            "\r          Equity-Ev   0%[                    ]       0  --.-KB/s               \rEquity-Evaluation-C 100%[===================>] 100.16K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-15 01:33:19 (932 KB/s) - ‘Equity-Evaluation-Corpus.zip.1’ saved [102568/102568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Le67qqg0ypdn",
        "colab_type": "code",
        "outputId": "541efc5d-00da-4990-f276-c5a10a72f7a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Equity-Evaluation-Corpus.zip\n",
            "replace Equity-Evaluation-Corpus.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: Equity-Evaluation-Corpus.csv  \n",
            "  inflating: README.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdMrdkW5ypSC",
        "colab_type": "code",
        "outputId": "527e043e-e960-447e-fe59-13fb109e2a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "07NMbgS0y5ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EEC = pd.read_csv('/content/Equity-Evaluation-Corpus.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHGlOXkfzHYL",
        "colab_type": "code",
        "outputId": "e7e5b62a-35b6-44c4-e115-8d4443c15da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "EEC[0:5]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Template</th>\n",
              "      <th>Person</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-En-mystery-05498</td>\n",
              "      <td>Alonzo feels angry.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-En-mystery-11722</td>\n",
              "      <td>Alonzo feels furious.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>furious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-En-mystery-11364</td>\n",
              "      <td>Alonzo feels irritated.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>irritated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-En-mystery-14320</td>\n",
              "      <td>Alonzo feels enraged.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>enraged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-En-mystery-14114</td>\n",
              "      <td>Alonzo feels annoyed.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>annoyed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      ID                 Sentence  \\\n",
              "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
              "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
              "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
              "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
              "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
              "\n",
              "                                 Template  Person Gender              Race  \\\n",
              "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "\n",
              "  Emotion Emotion word  \n",
              "0   anger        angry  \n",
              "1   anger      furious  \n",
              "2   anger    irritated  \n",
              "3   anger      enraged  \n",
              "4   anger      annoyed  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7PipGcPqDAsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "z5KUzX5ITJx4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EaIytYquTinV",
        "colab_type": "code",
        "outputId": "494e1137-9a69-43b3-efbd-85d62df65a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:47, 55.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-8shS1k9O0vD",
        "colab_type": "code",
        "outputId": "6ff511ec-0030-4f2f-a77f-3f8a275ce66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glove = KeyedVectors.load_word2vec_format('/content/' + 'gensim_glove.840B.300d.txt.bin', binary=True)\n",
        "print('The glove embedding has been loaded!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The glove embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iERp98e_DE0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Word2vec embeddings\n"
      ]
    },
    {
      "metadata": {
        "id": "89VbGhaRywxU",
        "colab_type": "code",
        "outputId": "2aba06b4-e7a4-4db7-ce63-a112ac5d6b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:21, 76.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilnFmeJ22HSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1d811a7-71f7-4f21-ee18-0b49a554f130"
      },
      "cell_type": "code",
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: /content/GoogleNews-vectors-negative300.bin already exists; do you wish to overwrite (y or n)? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_3sM3NFJO-Ic",
        "colab_type": "code",
        "outputId": "0834b6ec-089e-4d21-bea5-3bb031bf9fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/' + 'GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('The word2vec embedding has been loaded!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word2vec embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mk0C_cga8FVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load fasttext"
      ]
    },
    {
      "metadata": {
        "id": "PvnD-qf98HIT",
        "colab_type": "code",
        "outputId": "721e5c2d-6c0c-4627-b9d0-89a5d504d4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh\n",
            "To: /content/fasttext.bin\n",
            "2.42GB [00:58, 41.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VdnZkDWH8cqU",
        "colab_type": "code",
        "outputId": "12d09669-43e2-482f-8c29-011274c10a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "fasttext = KeyedVectors.load_word2vec_format('/content/' + 'fasttext.bin', binary=True)\n",
        "print('The fasttext embedding has been loaded!')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fasttext embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7NSiKG2DN2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load gender, racial name lists\n"
      ]
    },
    {
      "metadata": {
        "id": "cIyTozuW3V2H",
        "colab_type": "code",
        "outputId": "cc6a6eb2-1c93-428f-abca-3ff17df3fb8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "## Gender name lists\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-15 02:47:11--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20466 (20K) [text/plain]\n",
            "Saving to: ‘male.txt.1’\n",
            "\n",
            "male.txt.1          100%[===================>]  19.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-15 02:47:12 (146 MB/s) - ‘male.txt.1’ saved [20466/20466]\n",
            "\n",
            "--2019-03-15 02:47:13--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35751 (35K) [text/plain]\n",
            "Saving to: ‘female.txt.1’\n",
            "\n",
            "female.txt.1        100%[===================>]  34.91K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-15 02:47:13 (970 KB/s) - ‘female.txt.1’ saved [35751/35751]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Du8iVH8ZBApb",
        "colab_type": "code",
        "outputId": "c287ef8d-9b92-41aa-a3e1-374496618f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "cell_type": "code",
      "source": [
        "## Racial names lists\n",
        "!wget https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-15 02:47:14--  https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 921600 (900K) [text/plain]\n",
            "Saving to: ‘Black-Male-Names.csv.1’\n",
            "\n",
            "\rBlack-Male-Names.cs   0%[                    ]       0  --.-KB/s               \rBlack-Male-Names.cs 100%[===================>] 900.00K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-03-15 02:47:14 (11.8 MB/s) - ‘Black-Male-Names.csv.1’ saved [921600/921600]\n",
            "\n",
            "--2019-03-15 02:47:15--  https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1149042 (1.1M) [text/plain]\n",
            "Saving to: ‘White-Male-Names.csv.1’\n",
            "\n",
            "White-Male-Names.cs 100%[===================>]   1.10M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-03-15 02:47:16 (14.7 MB/s) - ‘White-Male-Names.csv.1’ saved [1149042/1149042]\n",
            "\n",
            "--2019-03-15 02:47:17--  https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121903 (119K) [text/plain]\n",
            "Saving to: ‘White-Female-Names.csv.1’\n",
            "\n",
            "White-Female-Names. 100%[===================>] 119.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-15 02:47:17 (3.16 MB/s) - ‘White-Female-Names.csv.1’ saved [121903/121903]\n",
            "\n",
            "--2019-03-15 02:47:18--  https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64757 (63K) [text/plain]\n",
            "Saving to: ‘Black-Female-Names.csv.1’\n",
            "\n",
            "Black-Female-Names. 100%[===================>]  63.24K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-15 02:47:18 (2.47 MB/s) - ‘Black-Female-Names.csv.1’ saved [64757/64757]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DeCv7ip13uN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXx6x2vGEshx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get frequency list (used in calculating sentence embeddings)"
      ]
    },
    {
      "metadata": {
        "id": "MWwGFIWGXqU7",
        "colab_type": "code",
        "outputId": "b0f98a73-7b56-4cb5-c7d9-be2bc429ef5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SIF' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRf-8VO3X0y7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wikiWordsPath = '/content' + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZi3h1qOBSap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load white/black names\n",
        "2400 names each side"
      ]
    },
    {
      "metadata": {
        "id": "dpuRepkwM0Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is for male names, don't run it when testing on female tasks\n",
        "word_list_male = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-V9S_T5FBXLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f = open('/content/White-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i=0\n",
        "for line in f:\n",
        "  i +=1\n",
        "  word_list_male.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()\n",
        "f = open('/content/Black-Male-Names.csv', 'r+')\n",
        "i=0\n",
        "f.readline()\n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_male.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjMZUac-B4ga",
        "colab_type": "code",
        "outputId": "334b8e11-4b29-4647-d2ca-17cc031bd91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list_male)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "dn7PreIglKYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list_female = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKdc4FQcE4s3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/White-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i =0 \n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_female.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()\n",
        "f = open('/content/Black-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_female.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vA6OIHCFgeI",
        "colab_type": "code",
        "outputId": "78dc0875-95c3-4c76-8e91-230994845ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list_female)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "TWXuqqFmE1_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load gender names(Not used in Racial Debiasing)"
      ]
    },
    {
      "metadata": {
        "id": "Rog_F2625pyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/male.txt', 'r+')\n",
        "i = 0\n",
        "word_list= []\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D75vc0Q86cIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/female.txt', 'r+')\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1pLLoV-6gSv",
        "colab_type": "code",
        "outputId": "5536832f-a1c2-47de-c653-2a1961e8241e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "0dFRyTKXc4WR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiemments"
      ]
    },
    {
      "metadata": {
        "id": "6iZFRcuzwmZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Sentence:\n",
        "    \n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itl-QRYavh9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "# calculate similarity scores on raw embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_raw(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6KBvMZJGRGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "#cn_embeddings is a glocal variable\n",
        "# calculate similarity scores on CN embeddings\n",
        "def run_conceptor(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha = 1): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    sentiment_emb = negC.dot(model[sentiment].T).T\n",
        "    proj1 = embedding1.dot(sentiment_emb)/norm(sentiment_emb)\n",
        "    proj2 = embedding2.dot(sentiment_emb)/norm(sentiment_emb)\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9IfreIwLQWqK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Use all male names to find conceptor using word2vec\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list_male if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64ZwrPJKQaAK",
        "colab_type": "code",
        "outputId": "bb24fd1a-71e0-4886-d427-196bd208487b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3657, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "gtceGUSqxVPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VC8jpWpFFq1y",
        "colab_type": "code",
        "outputId": "7731aa29-cf00-423e-e3e3-925572d2684a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          19.359635  3.104938e-57       12.406725  1.566748e-29\n",
            "fear           21.366772  2.309479e-65       13.206601  1.415429e-32\n",
            "joy            11.707836  6.245311e-27        4.849662  1.866064e-06\n",
            "sadness        17.006111  1.142249e-47        8.030925  1.499917e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wiS7qGemQ0Hb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Use all female names to find conceptor using word2vec\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list_female if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nqBE6INvU93r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZGbZvUlgE3H",
        "colab_type": "code",
        "outputId": "113ce5fc-0512-44dd-ff90-ee0d68c3e38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, female 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, female 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          13.849456  4.572745e-35        7.675373  1.669784e-13\n",
            "fear            8.261900  3.016258e-15        0.190049  8.493809e-01\n",
            "joy             5.400960  1.228679e-07        6.000689  4.920373e-09\n",
            "sadness        19.543729  5.545095e-58       18.106588  3.877847e-52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RumpnNDpq57m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list_male if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PavqP7YWCsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'glove', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-6Z9ihtF94k",
        "colab_type": "code",
        "outputId": "4bc19b8e-d269-4714-d5e7-863211a74b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, male 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, male 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -39.229215  5.467233e-130      -24.874147   2.729677e-79\n",
            "fear          -53.682502  1.007069e-170      -43.764183  8.979959e-144\n",
            "joy           -36.353356  1.032966e-120      -28.840793   2.160724e-94\n",
            "sadness       -22.533354   4.817098e-70      -21.893513   1.758025e-67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M0XiQdVMRE1k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list_female if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifykhtkiVCic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'glove', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PHkyqqWgZhk",
        "colab_type": "code",
        "outputId": "75400158-da7a-4cef-eed0-9b1b3ccd44bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, female 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, female 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger         -25.594525   4.332972e-82      -22.129255  1.992961e-68\n",
            "fear          -33.008122  2.269988e-109      -29.898306  2.784183e-98\n",
            "joy           -29.708214   1.378851e-97      -24.183388  1.386411e-76\n",
            "sadness       -15.018152   1.128162e-39      -16.582704  5.910297e-46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04hAVdzO80en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list_male if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLYZ68Q6vXwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9q1Ls4f1GdpE",
        "colab_type": "code",
        "outputId": "33c4f1ea-5a79-4254-bf33-61fe224f9a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, male 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, male 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -24.943738   1.461045e-79      -20.144836   2.012982e-60\n",
            "fear          -38.831695  9.875491e-129      -36.201127  3.289849e-120\n",
            "joy           -23.820355   3.732282e-75      -24.174769   1.498940e-76\n",
            "sadness       -19.571735   4.267023e-58      -17.292249   7.895303e-49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cw3AVmYSZci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list_female if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xV8OlU9UacY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZA8Bf0ignW2",
        "colab_type": "code",
        "outputId": "634c9300-28af-4403-aa78-6cec37aafc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, female 4800 names')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, female 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger           9.036385  1.130757e-17        4.293546  2.281516e-05\n",
            "fear            3.073295  2.283697e-03       -4.045877  6.421761e-05\n",
            "joy           -16.240469  1.423592e-44       -6.334529  7.338682e-10\n",
            "sadness         4.786356  2.512300e-06        0.400246  6.892201e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFapDcejVntk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using averaged sentiment embeddings"
      ]
    },
    {
      "metadata": {
        "id": "kRYsz7qiV-Ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "# calculate similarity scores on raw embeddings\n",
        "def run_raw(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOJbKd2kVwc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "# calculate similarity scores on CN embeddings\n",
        "def run_conceptor(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =1): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0)   \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    sen_embeddings = negC.dot(sen_embeddings.T).T\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFkCnIDDWdgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list_male if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gutvU6j4V4LH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001) \n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4poqfP2HFQI",
        "colab_type": "code",
        "outputId": "ccb80c92-8af1-4c99-c613-f2d0e4527235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male 4800 names, averaged sentimnent vector')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male 4800 names, averaged sentimnent vector\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          18.876432  2.863949e-55       13.611612  3.853190e-34\n",
            "fear           18.281446  7.540234e-53       11.406851  7.872486e-26\n",
            "joy            14.240858  1.340659e-36       10.060823  4.472136e-21\n",
            "sadness        15.365000  4.667011e-41       11.866843  1.618999e-27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q2ZjwsXnRpl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list_female if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5EzflVRUWksZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyqNSdmqg6Uz",
        "colab_type": "code",
        "outputId": "633be1de-4219-4b73-9919-c5112ead4bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, female 4800 names, averaged sentiment emb')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, female 4800 names, averaged sentiment emb\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger           6.118688  2.533850e-09        2.949185    0.003401\n",
            "fear            4.115710  4.820979e-05        0.476732    0.633851\n",
            "joy             1.940412  5.313473e-02        2.220383    0.027035\n",
            "sadness         2.070742  3.911770e-02        1.391250    0.165036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X-idjANoWlWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list_male if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUewIufVWq6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'glove', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rx5SPbNFHfg8",
        "colab_type": "code",
        "outputId": "05bb6fab-94c4-4dbc-e3a8-6062ca580788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, male 4800 names, averaged sentiment vector')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, male 4800 names, averaged sentiment vector\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -33.357260  1.393124e-110      -38.749684  1.798226e-128\n",
            "fear          -41.600778  2.538149e-137      -40.133508  8.101200e-133\n",
            "joy           -48.753785  7.681814e-158      -38.839614  9.320546e-129\n",
            "sadness       -40.561857  3.825451e-134      -38.350224  3.369603e-127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4wbnJjRSALp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list_female if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljmJ9ZbDWrWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'glove', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhhJCudrhPnS",
        "colab_type": "code",
        "outputId": "15d495bd-eec4-49fe-ab52-af775b7f8f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, female 4800 names, average sentiment emb')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, female 4800 names, average sentiment emb\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -24.210266   1.087004e-76      -29.729904   1.148516e-97\n",
            "fear          -33.929640  1.483594e-112      -35.047935  2.335524e-116\n",
            "joy           -30.262349   1.316721e-99      -32.714851  2.394678e-108\n",
            "sadness       -33.264375  2.922746e-110      -31.740498  6.492887e-105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PJ3AHZS3WzIb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list_male if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EEFY9sylWzfw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001, 1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rc0KcOP-g858",
        "colab_type": "code",
        "outputId": "fbdfa530-9f8e-4058-c3f1-be628c4d1e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, male, 4k names, averaged sentiment emb')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, male, 4k names, averaged sentiment emb\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -46.225740  7.524439e-151      -44.888416  4.866403e-147\n",
            "fear          -40.925205  2.918379e-135      -39.645938  2.684539e-131\n",
            "joy           -43.957295  2.444131e-144      -39.509312  7.195105e-131\n",
            "sadness       -44.227992  3.970227e-145      -39.335051  2.538114e-130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4yNSFxfjSFtA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list_female if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADoqYIRFW3iY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p=[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_raw(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001,1)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJwF08B1hfmk",
        "colab_type": "code",
        "outputId": "19933550-ca9e-4c16-aff8-00379429acc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, female 4800 names, averaged sentiment emb')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, female 4800 names, averaged sentiment emb\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger          12.255394  5.795978e-29        2.364344    0.018609\n",
            "fear            7.172205  4.445886e-12       -1.922682    0.055334\n",
            "joy            -0.056098  9.552957e-01       -2.137452    0.033256\n",
            "sadness         5.408571  1.181476e-07       -2.410683    0.016439\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
