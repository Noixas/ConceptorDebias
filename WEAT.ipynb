{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WEAT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/master/WEAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "l8Me4_OyFyKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# WEAT Algorithm\n",
        "## Test Statistic"
      ]
    },
    {
      "metadata": {
        "id": "mf6_liysF8en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# returns s(w, A, B) for all w in W (passed as argument). Shape: n_words (in W) x 1\n",
        "def swAB(W, A, B):\n",
        "  #Calculate cosine-similarity between W and A, W and B\n",
        "  WA = cosine_similarity(W,A)\n",
        "  WB = cosine_similarity(W,B)\n",
        "  #print('WA shape: ', WA.shape)\n",
        "  #Take mean along columns\n",
        "  WAmean = np.mean(WA, axis = 1)\n",
        "  WBmean = np.mean(WB, axis = 1)\n",
        "  \n",
        "  #print('sWAB shape: ', WAmean.shape)\n",
        "  \n",
        "  return (WAmean - WBmean)\n",
        "  \n",
        "def test_statistic(X, Y, A, B):\n",
        "  return (sum(swAB(X, A, B)) - sum(swAB(Y, A, B)))\n",
        "\n",
        "def weat_effect_size(X, Y, A, B, embd):\n",
        "  #Convert the set of words to matrix\n",
        "  Xmat = np.array([embd[w] for w in X if w in embd])\n",
        "  Ymat = np.array([embd[w] for w in Y if w in embd])\n",
        "  Amat = np.array([embd[w] for w in A if w in embd])\n",
        "  Bmat = np.array([embd[w] for w in B if w in embd])\n",
        "  \n",
        "  # Find X U Y\n",
        "  XuY = list(set(X).union(Y))\n",
        "  XuYmat = []\n",
        "  for w in XuY:\n",
        "    if w in embd:\n",
        "      XuYmat.append(embd[w])\n",
        "  XuYmat = np.array(XuYmat)\n",
        "  print('X U Y Shape: ', XuYmat.shape)\n",
        "  \n",
        "  d = (np.mean(swAB(Xmat,Amat,Bmat)) - np.mean(swAB(Ymat,Amat,Bmat)))/np.std(swAB(XuYmat, Amat, Bmat))\n",
        "  \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8foGwVSGI16",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## P-Value"
      ]
    },
    {
      "metadata": {
        "id": "ZDy-duFOFj71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from itertools import combinations, filterfalse\n",
        "\n",
        "def random_permutation(iterable, r=None):\n",
        "  pool = tuple(iterable)\n",
        "  r = len(pool) if r is None else r\n",
        "  return tuple(random.sample(pool, r))\n",
        "\n",
        "def weat_p_value(X, Y, A, B, embd, sample):\n",
        "  size_of_permutation = min(len(X), len(Y))\n",
        "  X_Y = X + Y\n",
        "  test_stats_over_permutation = []\n",
        "  \n",
        "  Xmat = np.array([embd[w] for w in X if w in embd])\n",
        "  Ymat = np.array([embd[w] for w in Y if w in embd])\n",
        "  Amat = np.array([embd[w] for w in A if w in embd])\n",
        "  Bmat = np.array([embd[w] for w in B if w in embd])\n",
        "  \n",
        "  if not sample:\n",
        "      permutations = combinations(X_Y, size_of_permutation)\n",
        "  else:\n",
        "      permutations = [random_permutation(X_Y, size_of_permutation) for s in range(sample)]\n",
        "      \n",
        "  for Xi in permutations:\n",
        "    Yi = filterfalse(lambda w:w in Xi, X_Y)\n",
        "    Ximat = np.array([embd[w] for w in Xi if w in embd])\n",
        "    Yimat = np.array([embd[w] for w in Yi if w in embd])\n",
        "    test_stats_over_permutation.append(test_statistic(Ximat, Yimat, Amat, Bmat))\n",
        "    \n",
        "  unperturbed = test_statistic(Xmat, Ymat, Amat, Bmat)\n",
        "  \n",
        "  is_over = np.array([o > unperturbed for o in test_stats_over_permutation])\n",
        "  print(\"All: \", test_stats_over_permutation)\n",
        "  print(\"Unpertrubed: \", unperturbed)\n",
        "  return is_over.sum() / is_over.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbRMmhwbGL98",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test on sample input"
      ]
    },
    {
      "metadata": {
        "id": "upscdvtwFm0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = [\"bagpipe\", \"cello\", \"guitar\", \"lute\", \"trombone\", \"banjo\", \"clarinet\", \"harmonica\", \"mandolin\", \"trumpet\", \"bassoon\", \"drum\", \"harp\", \"oboe\", \"tuba\", \"bell\", \"fiddle\", \"harpsichord\", \"piano\", \"viola\", \"bongo\",\n",
        "\"flute\", \"horn\", \"saxophone\", \"violin\"] #Instruments\n",
        "Y = [\"arrow\", \"club\", \"gun\", \"missile\", \"spear\", \"axe\", \"dagger\", \"harpoon\", \"pistol\", \"sword\", \"blade\", \"dynamite\", \"hatchet\", \"rifle\", \"tank\", \"bomb\", \"firearm\", \"knife\", \"shotgun\", \"teargas\", \"cannon\", \"grenade\",\n",
        "    \"mace\", \"slingshot\", \"whip\"] #Weapons\n",
        "A = [\"caress\", \"freedom\", \"health\", \"love\", \"peace\", \"cheer\", \"friend\", \"heaven\", \"loyal\", \"pleasure\", \"diamond\", \"gentle\", \"honest\", \"lucky\", \"rainbow\", \"diploma\", \"gift\", \"honor\", \"miracle\", \"sunrise\", \"family\",\n",
        "    \"happy\", \"laughter\", \"paradise\", \"vacation\"] #Pleasant\n",
        "B = [\"abuse\", \"crash\", \"filth\", \"murder\", \"sickness\", \"accident\", \"death\", \"grief\", \"poison\", \"stink\", \"assault\", \"disaster\", \"hatred\", \"pollute\", \"tragedy\", \"divorce\", \"jail\", \"poverty\", \"ugly\", \"cancer\", \"kill\", \"rotten\",\n",
        "    \"vomit\", \"agony\", \"prison\"] #Unpleasant\n",
        "\n",
        "#Load word embeddings\n",
        "#load gensim formatted Full Glove embeddings\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "resourceFile = '/content/'\n",
        "\n",
        "\n",
        "glove = KeyedVectors.load_word2vec_format(resourceFile + 'gensim_glove.840B.300d.txt.bin', binary=True)\n",
        "print('The glove embedding has been loaded!')\n",
        "\n",
        "print('WEAT d = ', weat_effect_size(X, Y, A, B, glove))\n",
        "print('WEAT p = ', weat_p_value(X, Y, A, B, glove, 1000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfwYNFl2ckGy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## WEAT with conceptor debiased embeddings"
      ]
    },
    {
      "metadata": {
        "id": "xEuq-Lt5ctV2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compute the conceptor matrix for all words and gender specific words."
      ]
    },
    {
      "metadata": {
        "id": "HAG4oqwIc1Z3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compute the conceptor matrix\n",
        "def post_process_cn_matrix(x, alpha = 2):\n",
        "  print(\"starting...\")\n",
        "  #x = orig_embd.vectors\n",
        "  print(x.shape)\n",
        "  \n",
        "  #Calculate the correlation matrix\n",
        "  R = x.dot(x.T)/(x.shape[1])\n",
        "  print(\"R calculated\")\n",
        "  print('Memory', psutil.virtual_memory())\n",
        "  #Calculate the conceptor matrix\n",
        "  C = R @ (np.linalg.inv(R + alpha ** (-2) * np.eye(x.shape[0])))\n",
        "  print(\"C calculated\")\n",
        "  print('Memory', psutil.virtual_memory())\n",
        "  #Calculate the negation of the conceptor matrix\n",
        "  negC = np.eye(x.shape[0]) - C\n",
        "  print(\"negC calculated\")\n",
        "  print('Memory', psutil.virtual_memory())\n",
        "  #Post-process the vocab matrix\n",
        "  newX = (negC @ x).T\n",
        "  print(newX.shape)\n",
        "  return newX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FusU4Guyyc1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load all vectors from **glove**"
      ]
    },
    {
      "metadata": {
        "id": "-bNIpTH7y4e2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load word embeddings\n",
        "#download gensim formatted Full Glove embeddings\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "resourceFile = '/content/'\n",
        "\n",
        "glove = KeyedVectors.load_word2vec_format(resourceFile + 'gensim_glove.840B.300d.txt.bin', binary=True)\n",
        "print('The glove embedding has been loaded!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6ZSpFtFy_bQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load all vectors from **Word2Vec**"
      ]
    },
    {
      "metadata": {
        "id": "7UbNQ5TszI7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load gensim formatted Full Word2vec embeddings\n",
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "#!gunzip GoogleNews-vectors-negative300.bin.gz\n",
        "  \n",
        "import gensim\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "resourceFile = '/content/'\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format(resourceFile + 'GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('The word2vec embedding has been loaded!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHaXxx5L3Ugb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load embeddings of all words from the ref. wordlist from a specific embedding"
      ]
    },
    {
      "metadata": {
        "id": "8WBI1VED3bpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_all_vectors(embd, wikiWordsPath):\n",
        "  all_words_index = {}\n",
        "  all_words_mat = []\n",
        "  with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    ind = 0\n",
        "    for line in f_in:\n",
        "      word = line.split(' ')[0]\n",
        "      if word in embd:\n",
        "        all_words_index[word] = ind\n",
        "        all_words_mat.append(embd[word])\n",
        "        ind = ind+1\n",
        "        \n",
        "  return all_words_index, all_words_mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjtc01gf8aR4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conceptor all words and store it in a dictonary"
      ]
    },
    {
      "metadata": {
        "id": "GeoHVWtg8jkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF\n",
        "wikiWordsPath = resourceFile + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "all_words_index, all_words_mat = load_all_vectors(glove, wikiWordsPath)\n",
        "all_words_cn = post_process_cn_matrix(all_words_mat)\n",
        "\n",
        "#Store all conceptored words in a dictonary\n",
        "all_words = {}\n",
        "for word, index in all_words_index.items():\n",
        "  all_words[word] = all_words_cn[index,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M5TAyWbzXcU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load embeddings of all gender-specific words (male_1, male_2, female_1, female_2) from a specific embedding"
      ]
    },
    {
      "metadata": {
        "id": "oxeeZPzZzmDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_gender_vectors(embd, gender_words):\n",
        "  gender_embd_index = {}\n",
        "  gender_embd_mat = []\n",
        "  ind = 0\n",
        "  for word in gender_words:\n",
        "    if word in embd:\n",
        "      gender_embd_index[word] = ind\n",
        "      gender_embd_mat.append(embd[word])\n",
        "      ind = ind+1\n",
        "      \n",
        "  return gender_embd_index, gender_embd_mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kB5QzT6u-pRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conceptor all gender words and store it in a dictonary"
      ]
    },
    {
      "metadata": {
        "id": "r-XJJf1O-yBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "male = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]\n",
        "female = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
        "male_2 = [\"brother\", \"father\", \"uncle\", \"grandfather\", \"son\", \"he\", \"his\", \"him\"]\n",
        "female_2 = [\"sister\", \"mother\", \"aunt\", \"grandmother\", \"daughter\", \"she\", \"hers\", \"he\"]\n",
        "gender_words_list = male + female + male_2 + female_2\n",
        "\n",
        "gender_words_index, gender_words_mat = load_gender_words(glove, gender_words_list)\n",
        "gender_words_cn = post_process_cn_matrix(gender_words_mat)\n",
        "\n",
        "#Store all conceptored words in a dictonary\n",
        "gender_words = {}\n",
        "for word, index in gender_words_index.items():\n",
        "  gender_words[word] = gender_words_cn[index,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAdi5tlZGRzL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## WEAT algorithm from GITHUB gist\n",
        "REF: https://gist.github.com/SandyRogers/e5c2e938502a75dcae25216e4fae2da5"
      ]
    },
    {
      "metadata": {
        "id": "2YM0FV9SFrWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WEATTest(object):\n",
        "    \"\"\"\n",
        "    Perform WEAT (Word Embedding Association Test) bias tests on a language model.\n",
        "    Follows from Caliskan et al 2017 (10.1126/science.aal4230).\n",
        "    \"\"\"\n",
        "    \n",
        "    instruments = [\"bagpipe\", \"cello\", \"guitar\", \"lute\", \"trombone\", \"banjo\", \"clarinet\", \"harmonica\", \"mandolin\", \"trumpet\", \"bassoon\", \"drum\", \"harp\", \"oboe\", \"tuba\", \"bell\", \"fiddle\", \"harpsichord\", \"piano\", \"viola\", \"bongo\",\n",
        "\"flute\", \"horn\", \"saxophone\", \"violin\"]\n",
        "    weapons = [\"arrow\", \"club\", \"gun\", \"missile\", \"spear\", \"axe\", \"dagger\", \"harpoon\", \"pistol\", \"sword\", \"blade\", \"dynamite\", \"hatchet\", \"rifle\", \"tank\", \"bomb\", \"firearm\", \"knife\", \"shotgun\", \"teargas\", \"cannon\", \"grenade\",\n",
        "    \"mace\", \"slingshot\", \"whip\"]\n",
        "    flowers = [\"aster\", \"clover\", \"hyacinth\", \"marigold\", \"poppy\", \"azalea\", \"crocus\", \"iris\", \"orchid\", \"rose\", \"blue-bell\", \"daffodil\", \"lilac\", \"pansy\", \"tulip\", \"buttercup\", \"daisy\", \"lily\", \"peony\", \"violet\", \"carnation\", \"gladiola\", \"magnolia\", \"petunia\", \"zinnia\"]\n",
        "    insects = [\"ant\", \"caterpillar\", \"flea\", \"locust\", \"spider\", \"bedbug\", \"centipede\", \"fly\", \"maggot\", \"tarantula\", \"bee\", \"cockroach\", \"gnat\", \"mosquito\", \"termite\", \"beetle\", \"cricket\", \"hornet\", \"moth\", \"wasp\", \"blackfly\",\n",
        "    \"dragonfly\", \"horsefly\", \"roach\", \"weevil\"]\n",
        "    pleasant = [\"caress\", \"freedom\", \"health\", \"love\", \"peace\", \"cheer\", \"friend\", \"heaven\", \"loyal\", \"pleasure\", \"diamond\", \"gentle\", \"honest\", \"lucky\", \"rainbow\", \"diploma\", \"gift\", \"honor\", \"miracle\", \"sunrise\", \"family\",\n",
        "    \"happy\", \"laughter\", \"paradise\", \"vacation\"]\n",
        "    unpleasant = [\"abuse\", \"crash\", \"filth\", \"murder\", \"sickness\", \"accident\", \"death\", \"grief\", \"poison\", \"stink\", \"assault\", \"disaster\", \"hatred\", \"pollute\", \"tragedy\", \"divorce\", \"jail\", \"poverty\", \"ugly\", \"cancer\", \"kill\", \"rotten\",\n",
        "    \"vomit\", \"agony\", \"prison\"]\n",
        "    math = [\"math\", \"algebra\", \"geometry\", \"calculus\", \"equations\", \"computation\", \"numbers\", \"addition\"]\n",
        "    arts = [\"poetry\", \"art\", \"dance\", \"literature\", \"novel\", \"symphony\", \"drama\", \"sculpture\"]\n",
        "    male = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]\n",
        "    female = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
        "    science = [\"science\", \"technology\", \"physics\", \"chemistry\", \"Einstein\", \"NASA\", \"experiment\", \"astronomy\"]\n",
        "    arts_2 = [\"poetry\", \"art\", \"Shakespeare\", \"dance\", \"literature\", \"novel\", \"symphony\", \"drama\"]\n",
        "    male_2 = [\"brother\", \"father\", \"uncle\", \"grandfather\", \"son\", \"he\", \"his\", \"him\"]\n",
        "    female_2 = [\"sister\", \"mother\", \"aunt\", \"grandmother\", \"daughter\", \"she\", \"hers\", \"he\"]\n",
        "    mental_disease = [\"sad\", \"hopeless\", \"gloomy\", \"tearful\", \"miserable\", \"depressed\"]\n",
        "    physical_disease = [\"sick\", \"illness\", \"influenza\", \"disease\", \"virus\", \"cancer\"]\n",
        "    temporary = [\"impermanent\", \"unstable\", \"variable\", \"fleeting\", \"short-term\", \"brief\", \"occasional\"]\n",
        "    permanent = [\"stable\", \"always\", \"constant\", \"persistent\", \"chronic\", \"prolonged\", \"forever\"]\n",
        "    \n",
        "    def __init__(self, model):\n",
        "        \"\"\"Setup a Word Embedding Association Test for a given spaCy language model.\n",
        "        \n",
        "        EXAMPLE:\n",
        "            >>> nlp = spacy.load('en_core_web_md')\n",
        "            >>> test = WEATTest(nlp)\n",
        "            >>> test.run_test(WEATTest.instruments, WEATTest.weapon, WEATTest.pleasant, WEATTest.unpleasant)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "\n",
        "    @staticmethod\n",
        "    def word_association_with_attribute(self, w, A, B):\n",
        "        return np.mean([cosine_similarity(np.array(w).reshape(1,-1),np.array(a).reshape(1,-1)) for a in A]) - np.mean([cosine_similarity(np.array(w).reshape(1,-1),np.array(b).reshape(1,-1)) for b in B])\n",
        "\n",
        "    @staticmethod\n",
        "    def differential_assoication(self, X, Y, A, B):\n",
        "        return np.sum([self.word_association_with_attribute(self, x, A, B) for x in X]) - np.sum([self.word_association_with_attribute(self, y, A, B) for y in Y])\n",
        "\n",
        "    @staticmethod\n",
        "    def weat_effect_size(self, X, Y, A, B):\n",
        "        return (\n",
        "            np.mean([self.word_association_with_attribute(self, x, A, B) for x in X]) -\n",
        "            np.mean([self.word_association_with_attribute(self, y, A, B) for y in Y])\n",
        "        ) / np.std([self.word_association_with_attribute(self, w, A, B) for w in X + Y])\n",
        "\n",
        "    @staticmethod\n",
        "    def random_permutation(self, iterable, r=None):\n",
        "        pool = tuple(iterable)\n",
        "        r = len(pool) if r is None else r\n",
        "        return tuple(random.sample(pool, r))\n",
        "\n",
        "    @staticmethod\n",
        "    def weat_p_value(self, X, Y, A, B, sample):\n",
        "        size_of_permutation = min(len(X), len(Y))\n",
        "        X_Y = X + Y\n",
        "        observed_test_stats_over_permutations = []\n",
        "\n",
        "        if not sample:\n",
        "            permutations = combinations(X_Y, size_of_permutation)\n",
        "        else:\n",
        "            permutations = [self.random_permutation(self, X_Y, size_of_permutation) for s in range(sample)]\n",
        "        print(np.array(X_Y).shape)\n",
        "        for Xi in permutations:\n",
        "            Yi = filterfalse(lambda w:w in Xi, X_Y)\n",
        "            observed_test_stats_over_permutations.append(self.differential_assoication(self, Xi, Yi, A, B))\n",
        "\n",
        "        unperturbed = self.differential_assoication(self, X, Y, A, B)\n",
        "        is_over = np.array([o > unperturbed for o in observed_test_stats_over_permutations])\n",
        "        return is_over.sum() / is_over.size\n",
        "\n",
        "    @staticmethod\n",
        "    def weat_stats(X, Y, A, B, self, sample_p=None):\n",
        "        test_statistic = self.differential_assoication(self, X, Y, A, B)\n",
        "        effect_size = self.weat_effect_size(self, X, Y, A, B)\n",
        "        p = self.weat_p_value(self, X, Y, A, B, sample=sample_p)\n",
        "        return test_statistic, effect_size, p\n",
        "\n",
        "    def run_test(self, target_1, target_2, attributes_1, attributes_2, sample_p=None):\n",
        "        \"\"\"Run the WEAT test for differential association between two \n",
        "        sets of target words and two seats of attributes.\n",
        "        \n",
        "        EXAMPLE:\n",
        "            >>> test.run_test(WEATTest.instruments, WEATTest.weapon, WEATTest.pleasant, WEATTest.unpleasant)\n",
        "            >>> test.run_test(a, b, c, d, sample_p=1000) # use 1000 permutations for p-value calculation\n",
        "            >>> test.run_test(a, b, c, d, sample_p=None) # use all possible permutations for p-value calculation\n",
        "            \n",
        "        RETURNS:\n",
        "            (d, e, p). A tuple of floats, where d is the WEAT Test statistic, \n",
        "            e is the effect size, and p is the one-sided p-value measuring the\n",
        "            (un)likeliness of the null hypothesis (which is that there is no\n",
        "            difference in association between the two target word sets and\n",
        "            the attributes).\n",
        "            \n",
        "            If e is large and p small, then differences in the model between \n",
        "            the attribute word sets match differences between the targets.\n",
        "        \"\"\"\n",
        "        X = [list(self.model[w]) for w in target_1]\n",
        "        Y = [list(self.model[w]) for w in target_2]\n",
        "        A = [list(self.model[w]) for w in attributes_1]\n",
        "        B = [list(self.model[w]) for w in attributes_2]\n",
        "        print(X)\n",
        "        return self.weat_stats(X, Y, A, B, self, sample_p)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I9dGN5fGQw-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code test"
      ]
    },
    {
      "metadata": {
        "id": "agNgns64tdBP",
        "colab_type": "code",
        "outputId": "05d3aae1-cb90-4a23-f675-757360296044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#nlp = spacy.load('glove')\n",
        "test = WEATTest(glove)\n",
        "test.run_test(WEATTest.instruments, WEATTest.weapons, WEATTest.pleasant, WEATTest.unpleasant, 1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The glove embedding has been loaded!\n",
            "X Shape:  (3, 300)\n",
            "Y Shape:  (3, 300)\n",
            "A Shape:  (2, 300)\n",
            "B Shape:  (2, 300)\n",
            "X U Y Shape:  (6, 300)\n",
            "WA shape:  (3, 2)\n",
            "sWAB shape:  (3,)\n",
            "WA shape:  (3, 2)\n",
            "sWAB shape:  (3,)\n",
            "WA shape:  (6, 2)\n",
            "sWAB shape:  (6,)\n",
            "WEAT d =  1.8613524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "agexIaaUujxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}