{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEC with CN(w2v, GloVe, Fasttext)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/ACL-cleanup/EEC_with_CN(w2v%2C_GloVe%2C_Fasttext).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Pz4EMOLUOuCL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load EEC\n",
        "REF: Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems. Svetlana Kiritchenko and Saif M. Mohammad. In Proceedings of *Sem, New Orleans, LA, USA, June 2018."
      ]
    },
    {
      "metadata": {
        "id": "WQJS8yEwygVb",
        "colab_type": "code",
        "outputId": "0b3fbd4f-3a8d-41ce-dba0-9df642172acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "# get EEC from web\n",
        "!wget http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-24 00:42:10--  http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip\n",
            "Resolving www.saifmohammad.com (www.saifmohammad.com)... 192.185.17.122\n",
            "Connecting to www.saifmohammad.com (www.saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102568 (100K) [application/zip]\n",
            "Saving to: ‘Equity-Evaluation-Corpus.zip’\n",
            "\n",
            "\r          Equity-Ev   0%[                    ]       0  --.-KB/s               \rEquity-Evaluation-C 100%[===================>] 100.16K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-24 00:42:10 (918 KB/s) - ‘Equity-Evaluation-Corpus.zip’ saved [102568/102568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Le67qqg0ypdn",
        "colab_type": "code",
        "outputId": "0ed92bb3-3444-4d6e-9f8f-798ac6149712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Equity-Evaluation-Corpus.zip\n",
            "  inflating: Equity-Evaluation-Corpus.csv  \n",
            "  inflating: README.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdMrdkW5ypSC",
        "colab_type": "code",
        "outputId": "b273366d-9e90-403d-f460-cc611e42133d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "#Load python libraries\n",
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')\n",
        "!wget https://raw.githubusercontent.com/jsedoc/ConceptorDebias/ACL-cleanup/Conceptors/conceptor_fxns.py\n",
        "from conceptor_fxns import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "--2019-03-24 00:42:15--  https://raw.githubusercontent.com/jsedoc/ConceptorDebias/ACL-cleanup/Conceptors/conceptor_fxns.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300 (2.2K) [text/plain]\n",
            "Saving to: ‘conceptor_fxns.py’\n",
            "\n",
            "conceptor_fxns.py   100%[===================>]   2.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 00:42:15 (21.2 MB/s) - ‘conceptor_fxns.py’ saved [2300/2300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "07NMbgS0y5ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EEC = pd.read_csv('/content/Equity-Evaluation-Corpus.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHGlOXkfzHYL",
        "colab_type": "code",
        "outputId": "307cef07-2537-42a0-a73b-738b2618bad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "EEC[0:5]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Template</th>\n",
              "      <th>Person</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-En-mystery-05498</td>\n",
              "      <td>Alonzo feels angry.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-En-mystery-11722</td>\n",
              "      <td>Alonzo feels furious.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>furious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-En-mystery-11364</td>\n",
              "      <td>Alonzo feels irritated.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>irritated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-En-mystery-14320</td>\n",
              "      <td>Alonzo feels enraged.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>enraged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-En-mystery-14114</td>\n",
              "      <td>Alonzo feels annoyed.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>annoyed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      ID                 Sentence  \\\n",
              "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
              "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
              "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
              "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
              "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
              "\n",
              "                                 Template  Person Gender              Race  \\\n",
              "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "\n",
              "  Emotion Emotion word  \n",
              "0   anger        angry  \n",
              "1   anger      furious  \n",
              "2   anger    irritated  \n",
              "3   anger      enraged  \n",
              "4   anger      annoyed  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "7PipGcPqDAsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "z5KUzX5ITJx4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EaIytYquTinV",
        "colab_type": "code",
        "outputId": "0ceef119-70a1-428f-8a9e-b5270bc037be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:48, 55.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-8shS1k9O0vD",
        "colab_type": "code",
        "outputId": "733f8604-0772-4ca8-bc7f-19b69a47559c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "glove = KeyedVectors.load_word2vec_format('/content/' + 'gensim_glove.840B.300d.txt.bin', binary=True)\n",
        "print('The glove embedding has been loaded!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The glove embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iERp98e_DE0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Word2vec embeddings\n"
      ]
    },
    {
      "metadata": {
        "id": "89VbGhaRywxU",
        "colab_type": "code",
        "outputId": "1bc6e971-7a14-44c3-d3af-bf5c7243340f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:23, 70.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilnFmeJ22HSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_3sM3NFJO-Ic",
        "colab_type": "code",
        "outputId": "78f4adf0-933b-4eb0-b8ef-591eab2655c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/' + 'GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('The word2vec embedding has been loaded!')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word2vec embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mk0C_cga8FVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load fasttext"
      ]
    },
    {
      "metadata": {
        "id": "PvnD-qf98HIT",
        "colab_type": "code",
        "outputId": "a776b064-50e7-45ad-a67f-9daa0aa6a42e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh\n",
            "To: /content/fasttext.bin\n",
            "2.42GB [00:42, 56.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VdnZkDWH8cqU",
        "colab_type": "code",
        "outputId": "b6ed9a69-f414-40f5-8f26-e3b9eae753ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "fasttext = KeyedVectors.load_word2vec_format('/content/' + 'fasttext.bin', binary=True)\n",
        "print('The fasttext embedding has been loaded!')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fasttext embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7NSiKG2DN2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load racial name lists\n"
      ]
    },
    {
      "metadata": {
        "id": "Du8iVH8ZBApb",
        "colab_type": "code",
        "outputId": "c9aad557-7da4-44ee-e00b-cd0d7318ab60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "cell_type": "code",
      "source": [
        "## Racial names lists\n",
        "!wget https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
        "!wget https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-24 00:54:52--  https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 921600 (900K) [text/plain]\n",
            "Saving to: ‘Black-Male-Names.csv’\n",
            "\n",
            "Black-Male-Names.cs 100%[===================>] 900.00K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-03-24 00:54:52 (12.1 MB/s) - ‘Black-Male-Names.csv’ saved [921600/921600]\n",
            "\n",
            "--2019-03-24 00:54:53--  https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1149042 (1.1M) [text/plain]\n",
            "Saving to: ‘White-Male-Names.csv’\n",
            "\n",
            "White-Male-Names.cs 100%[===================>]   1.10M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-03-24 00:54:54 (14.3 MB/s) - ‘White-Male-Names.csv’ saved [1149042/1149042]\n",
            "\n",
            "--2019-03-24 00:54:55--  https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121903 (119K) [text/plain]\n",
            "Saving to: ‘White-Female-Names.csv’\n",
            "\n",
            "White-Female-Names. 100%[===================>] 119.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-24 00:54:55 (3.11 MB/s) - ‘White-Female-Names.csv’ saved [121903/121903]\n",
            "\n",
            "--2019-03-24 00:54:56--  https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64757 (63K) [text/plain]\n",
            "Saving to: ‘Black-Female-Names.csv’\n",
            "\n",
            "Black-Female-Names. 100%[===================>]  63.24K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-24 00:54:56 (2.54 MB/s) - ‘Black-Female-Names.csv’ saved [64757/64757]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DeCv7ip13uN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXx6x2vGEshx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get frequency list (used in calculating sentence embeddings)"
      ]
    },
    {
      "metadata": {
        "id": "MWwGFIWGXqU7",
        "colab_type": "code",
        "outputId": "e5fae573-c5f4-4fe2-9f68-28f09aed9685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SIF'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 2.80 MiB | 20.61 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRf-8VO3X0y7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wikiWordsPath = '/content' + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZi3h1qOBSap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load white/black names\n",
        "Since there are only around 2400 names in black female name list, we consider using only 2400 names in each of the four lists."
      ]
    },
    {
      "metadata": {
        "id": "dpuRepkwM0Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is for male names, don't run it when testing on female tasks\n",
        "word_list_male = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-V9S_T5FBXLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f = open('/content/White-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i=0\n",
        "for line in f:\n",
        "  i +=1\n",
        "  word_list_male.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()\n",
        "f = open('/content/Black-Male-Names.csv', 'r+')\n",
        "i=0\n",
        "f.readline()\n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_male.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjMZUac-B4ga",
        "colab_type": "code",
        "outputId": "33038310-53cd-4012-8539-d9ee8bdad825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list_male)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "dn7PreIglKYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list_female = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKdc4FQcE4s3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/White-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i =0 \n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_female.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()\n",
        "f = open('/content/Black-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  word_list_female.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "  if i>=2400:\n",
        "    break\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vA6OIHCFgeI",
        "colab_type": "code",
        "outputId": "679e4777-5f85-4cf1-9616-da8220b86995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list_female)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "0dFRyTKXc4WR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ]
    },
    {
      "metadata": {
        "id": "jDiI4RKCUodg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Racial Debiasing Results\n",
        "Experiements are done using male and female names separately"
      ]
    },
    {
      "metadata": {
        "id": "6iZFRcuzwmZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Sentence: # sentence class, \"raw\" means orignial sentence, \"tokens\" means tokenized sentence\n",
        "    \n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itl-QRYavh9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "# calculate similarity scores on raw embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim_raw_sent_emb(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values()) # get total frequencies\n",
        "    model = eval(model_str)\n",
        "    \n",
        "    tokens1 =  sent1.tokens # get tokens of sentence 1\n",
        "    tokens2 =  sent2.tokens # get tokens of sentence 2\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()] # get tokens that both in sentence 1 and word embeddings\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()] # get tokens that both in sentence 2 and word embeddings\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1] # get weights of each word in sentence 1 based on their inverse frequencies on wiki\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2] # get weights of each word in sentence 2 based on their inverse frequencies on wiki\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)  # get sentence 1 embedding\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2) # get sentence 2 embedding\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment]) # cos similarity\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment]) # cos similarity\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6KBvMZJGRGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "#cn_embeddings is a glocal variable\n",
        "# calculate similarity scores on CN embeddings\n",
        "def cos_sim_conceptor_sent_emb(cn_embeddings, sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha = 1): \n",
        "    total_freq = sum(freqs.values()) # get total frequencies\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    tokens1 =  sent1.tokens # get tokens of sentence 1\n",
        "    tokens2 =  sent2.tokens # get tokens of sentence 2\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()] # get tokens that both in sentence 1 and word embeddings\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()] # get tokens that both in sentence 2 and word embeddings\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1] # get weights of each word in sentence 1 based on their inverse frequencies on wiki\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2] # get weights of each word in sentence 2 based on their inverse frequencies on wiki\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1) # get sentence 1 embedding\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2) # get sentence 2 embedding\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]  \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC,_,_ = post_process_cn_matrix(cn_embeddings, alpha)\n",
        "    embedding1 = negC.dot(embedding1.T).T # CN sentence 1 \n",
        "    embedding2 = negC.dot(embedding2.T).T # CN sentence 2\n",
        "    embedding1 /= norm(embedding1) #normalize\n",
        "    embedding2 /= norm(embedding2) #normalize\n",
        "    sentiment_emb = negC.dot(model[sentiment].T).T #CN sentiment embedding\n",
        "    proj1 = embedding1.dot(sentiment_emb)/norm(sentiment_emb) #cos similarity\n",
        "    proj2 = embedding2.dot(sentiment_emb)/norm(sentiment_emb) #cos similarity\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtceGUSqxVPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def paired_t(model_str, gender_str, alpha):\n",
        "  model = eval(model_str)\n",
        "  if gender_str =='male':\n",
        "    word_list = word_list_male # word_list_male is a global variable\n",
        "  elif gender_str =='female':\n",
        "    word_list = word_list_female #word_list_female is a global variable\n",
        "  cn_embeddings = []\n",
        "  cn_embeddings.append([model[word] for word in word_list if word in model.vocab])\n",
        "  cn_embeddings = np.array(cn_embeddings[0])\n",
        "  p= []\n",
        "  for sen in ['anger','fear','joy', 'sadness']:\n",
        "    aa = []  # raw score for african american\n",
        "    ea = []  # raw score for european american\n",
        "    aa_cn = []  # CN score for african american\n",
        "    ea_cn = []  # cn score for european american\n",
        "    sent_sent = []  # sentence of certain sentiment\n",
        "    sent_aa = [] # sentence of certain sentiment for african american\n",
        "    sent_ea = [] # sentence of certain sentiment for european american\n",
        "    sent_sent = EEC[EEC['Emotion']==sen] # get sentence of certain sentiment\n",
        "    sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']==gender_str)]  #get AA gender sentences\n",
        "    sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']==gender_str) ] # get EA gender sentences\n",
        "   # print(len(sent_ea))\n",
        "    for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "      sentence1=Sentence(sen1)\n",
        "      sentence2=Sentence(sen2)\n",
        "      score1, score2 = cos_sim_raw_sent_emb(sen, sentence1, sentence2, model_str, frequencies, 0.0001)  #projection score on raw data\n",
        "      score3, score4 = cos_sim_conceptor_sent_emb(cn_embeddings, sen, sentence1, sentence2, model_str, frequencies, 0.0001, alpha)  #projection score on raw data\n",
        "      aa.append(score1) # raw score for african american\n",
        "      ea.append(score2) # raw score for european american\n",
        "      aa_cn.append(score3) # CN score for african american\n",
        "      ea_cn.append(score4) # CN score for european american\n",
        "    p1 = scipy.stats.ttest_rel(aa, ea) #paired t-test for raw data\n",
        "    p2 = scipy.stats.ttest_rel(aa_cn, ea_cn) #paired t-test for CN data\n",
        "    p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VC8jpWpFFq1y",
        "colab_type": "code",
        "outputId": "4f090589-effa-4b19-b62d-fc85268f0a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male 4800 names')\n",
        "p = paired_t('word2vec', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          19.359635  3.104938e-57       12.406725  1.566748e-29\n",
            "fear           21.366772  2.309479e-65       13.206601  1.415429e-32\n",
            "joy            11.707836  6.245311e-27        4.849662  1.866064e-06\n",
            "sadness        17.006111  1.142249e-47        8.030925  1.499917e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zHIt14PEAMCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "0ddc4601-bcb4-4d5b-8d4f-13fd905d9dbc"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, female 4800 names')\n",
        "p = paired_t('word2vec', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, female 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          13.849456  4.572745e-35        7.675373  1.669784e-13\n",
            "fear            8.261900  3.016258e-15        0.190049  8.493809e-01\n",
            "joy             5.400960  1.228679e-07        6.000689  4.920373e-09\n",
            "sadness        19.543729  5.545095e-58       18.106588  3.877847e-52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t-6Z9ihtF94k",
        "colab_type": "code",
        "outputId": "128a5bd5-5e6b-4fbc-8911-dbd38a0a0134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, male 4800 names')\n",
        "p = paired_t('glove', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, male 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -39.229215  5.467233e-130      -24.874147   2.729677e-79\n",
            "fear          -53.682502  1.007069e-170      -43.764183  8.979959e-144\n",
            "joy           -36.353356  1.032966e-120      -28.840793   2.160724e-94\n",
            "sadness       -22.533354   4.817098e-70      -21.893513   1.758025e-67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3PHkyqqWgZhk",
        "colab_type": "code",
        "outputId": "9328180c-379a-48b8-8505-79c5205d9c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, female 4800 names')\n",
        "p = paired_t('glove', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, female 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger         -25.594525   4.332972e-82      -22.129255  1.992961e-68\n",
            "fear          -33.008122  2.269988e-109      -29.898306  2.784183e-98\n",
            "joy           -29.708214   1.378851e-97      -24.183388  1.386411e-76\n",
            "sadness       -15.018152   1.128162e-39      -16.582704  5.910297e-46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9q1Ls4f1GdpE",
        "colab_type": "code",
        "outputId": "9aa8928d-c66a-4892-82ba-12b573fbedab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, male 4800 names')\n",
        "p = paired_t('fasttext', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, male 4800 names\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -24.943738   1.461045e-79      -20.144836   2.012982e-60\n",
            "fear          -38.831695  9.875491e-129      -36.201127  3.289849e-120\n",
            "joy           -23.820355   3.732282e-75      -24.174769   1.498940e-76\n",
            "sadness       -19.571735   4.267023e-58      -17.292249   7.895303e-49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sZA8Bf0ignW2",
        "colab_type": "code",
        "outputId": "1521435c-f7aa-479d-bdbd-cc3b504f075c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, female 4800 names')\n",
        "p = paired_t('fasttext', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, female 4800 names\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger           9.036385  1.130757e-17        4.293546  2.281516e-05\n",
            "fear            3.073295  2.283697e-03       -4.045877  6.421761e-05\n",
            "joy           -16.240469  1.423592e-44       -6.334529  7.338682e-10\n",
            "sadness         4.786356  2.512300e-06        0.400246  6.892201e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFapDcejVntk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Racial Debiasing Results using averaged sentiment embeddings"
      ]
    },
    {
      "metadata": {
        "id": "kRYsz7qiV-Ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "# calculate similarity scores on raw embeddings\n",
        "def cos_sim_raw_sent_emb_avg( sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values()) # get total frequencies\n",
        "    model = eval(model_str)\n",
        "    sen_list = EEC[EEC['Emotion']==sentiment]['Emotion word'].unique() # get words representing certain sentiment\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens # tokens of sentence 1\n",
        "    tokens2 =  sent2.tokens # tokens of sentence 2\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()] #tokens both in sentence 1 and word embeddings\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()] #tokens both in sentence 2 and word embeddings\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1] # get weights of each word in sentence 1 based on their inverse frequencies on wiki\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2] # get weights of each word in sentence 2 based on their inverse frequencies on wiki\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1)) # sentence 1 embedding\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2)) # sentence 2 embedding\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings) # cos similarity\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings) # cos similarity\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOJbKd2kVwc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "# calculate similarity scores on CN embeddings\n",
        "def cos_sim_conceptor_sent_emb_avg(cn_embeddings, sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =1): \n",
        "    total_freq = sum(freqs.values()) # get total frequencies\n",
        "    model = eval(model_str)\n",
        "    sen_list = EEC[EEC['Emotion']==sentiment]['Emotion word'].unique() # get words representing certain sentiment\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0)    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "    tokens1 =  sent1.tokens # tokens of sentence 1\n",
        "    tokens2 =  sent2.tokens # tokens of sentence 2\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()] #tokens both in sentence 1 and word embeddings\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()] #tokens both in sentence 2 and word embeddings\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1] # get weights of each word in sentence 1 based on their inverse frequencies on wiki \n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2] # get weights of each word in sentence 2 based on their inverse frequencies on wiki\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1) # sentence 1 embedding\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2) # sentence 2 embedding\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0] \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    #negC,_,_ = post_process_cn_matrix(cn_embeddings, alpha)\n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T # CN sentence 1 embedding\n",
        "    embedding2 = negC.dot(embedding2.T).T # CN sentence 2 embedding\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    sen_embeddings = negC.dot(sen_embeddings.T).T # CN sentiment embedding\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings) #cos similarity\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings) #cos similarity\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_UKnhC1buJy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def paired_t_avg_sent(model_str, gender_str, alpha):\n",
        "  model = eval(model_str)\n",
        "  if gender_str =='male':\n",
        "    word_list = word_list_male # word_list_male is a global variable\n",
        "  elif gender_str =='female':\n",
        "    word_list = word_list_female #word_list_female is a global variable\n",
        "  cn_embeddings = []\n",
        "  cn_embeddings.append([model[word] for word in word_list if word in model.vocab])\n",
        "  cn_embeddings = np.array(cn_embeddings[0])\n",
        "  p= []\n",
        "  for sen in ['anger','fear','joy', 'sadness']:\n",
        "    aa = [] # raw score for african american\n",
        "    ea = [] # raw score for european american\n",
        "    aa_cn = [] # CN score for african american\n",
        "    ea_cn = [] # CN score for european american\n",
        "    sent_sent = [] # sentence of certain sentiment\n",
        "    sent_aa = [] # sentence of certain sentiment for african american\n",
        "    sent_ea = [] # sentence of certain sentiment for european american\n",
        "    sent_sent = EEC[EEC['Emotion']==sen] # get sentence of certain sentiment\n",
        "    sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']==gender_str)] # get AA gender sentences\n",
        "    sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']==gender_str) ] # get EA gender sentences\n",
        "   # print(len(sent_ea))\n",
        "    for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "      sentence1=Sentence(sen1)\n",
        "      sentence2=Sentence(sen2)\n",
        "      score1, score2 = cos_sim_raw_sent_emb_avg(sen, sentence1, sentence2, model_str, frequencies, 0.0001) #projection score on raw data\n",
        "      score3, score4 = cos_sim_conceptor_sent_emb_avg(cn_embeddings, sen, sentence1, sentence2, model_str, frequencies, 0.0001, alpha) #projection score on CN data\n",
        "      aa.append(score1) # raw score for african american\n",
        "      ea.append(score2) # raw score for european american\n",
        "      aa_cn.append(score3) # CN score for african american\n",
        "      ea_cn.append(score4) # CN score for european american\n",
        "    p1 = scipy.stats.ttest_rel(aa, ea)  #paired t-test for raw data\n",
        "    p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)  #paired t-test for CN data\n",
        "    p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4poqfP2HFQI",
        "colab_type": "code",
        "outputId": "7b3bddd5-4d1b-4291-9a2e-2f9bd7f62dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male 4800 names, averaged sentimnent vector')\n",
        "p = paired_t_avg_sent('word2vec', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male 4800 names, averaged sentimnent vector\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          18.876432  2.863949e-55       13.611612  3.853190e-34\n",
            "fear           18.281446  7.540234e-53       11.406851  7.872486e-26\n",
            "joy            14.240858  1.340659e-36       10.060823  4.472136e-21\n",
            "sadness        15.365000  4.667011e-41       11.866843  1.618999e-27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jyqNSdmqg6Uz",
        "colab_type": "code",
        "outputId": "255410a6-5724-4c5a-ba5e-d53a834e1ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, female 4800 names, averaged sentiment emb')\n",
        "p = paired_t_avg_sent('word2vec', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, female 4800 names, averaged sentiment emb\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger           6.118688  2.533850e-09        2.949185    0.003401\n",
            "fear            4.115710  4.820979e-05        0.476732    0.633851\n",
            "joy             1.940412  5.313473e-02        2.220383    0.027035\n",
            "sadness         2.070742  3.911770e-02        1.391250    0.165036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rx5SPbNFHfg8",
        "colab_type": "code",
        "outputId": "7a0c7f55-cc81-41b2-8079-a84b10fc980c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, male 4800 names, averaged sentiment vector')\n",
        "p = paired_t_avg_sent('glove', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, male 4800 names, averaged sentiment vector\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -33.357260  1.393124e-110      -38.749684  1.798226e-128\n",
            "fear          -41.600778  2.538149e-137      -40.133508  8.101200e-133\n",
            "joy           -48.753785  7.681814e-158      -38.839614  9.320546e-129\n",
            "sadness       -40.561857  3.825451e-134      -38.350224  3.369603e-127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XhhJCudrhPnS",
        "colab_type": "code",
        "outputId": "2e0531cc-0657-42a1-e23b-0e5d836b1774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using GLOVE, female 4800 names, average sentiment emb')\n",
        "p = paired_t_avg_sent('glove', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using GLOVE, female 4800 names, average sentiment emb\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -24.210266   1.087004e-76      -29.729904   1.148516e-97\n",
            "fear          -33.929640  1.483594e-112      -35.047935  2.335524e-116\n",
            "joy           -30.262349   1.316721e-99      -32.714851  2.394678e-108\n",
            "sadness       -33.264375  2.922746e-110      -31.740498  6.492887e-105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rc0KcOP-g858",
        "colab_type": "code",
        "outputId": "8b46e84d-60fe-4605-ab54-a8993daa701f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, male, 4k names, averaged sentiment emb')\n",
        "p = paired_t_avg_sent('fasttext', 'male', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, male, 4k names, averaged sentiment emb\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -46.225740  7.524439e-151      -44.888416  4.866403e-147\n",
            "fear          -40.925205  2.918379e-135      -39.645938  2.684539e-131\n",
            "joy           -43.957295  2.444131e-144      -39.509312  7.195105e-131\n",
            "sadness       -44.227992  3.970227e-145      -39.335051  2.538114e-130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mJwF08B1hfmk",
        "colab_type": "code",
        "outputId": "dcc9edaa-f7ee-4e94-f50c-72e83f681e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using FASTTEXT, female 4800 names, averaged sentiment emb')\n",
        "p = paired_t_avg_sent('fasttext', 'female', 1)\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using FASTTEXT, female 4800 names, averaged sentiment emb\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger          12.255394  5.795978e-29        2.364344    0.018609\n",
            "fear            7.172205  4.445886e-12       -1.922682    0.055334\n",
            "joy            -0.056098  9.552957e-01       -2.137452    0.033256\n",
            "sadness         5.408571  1.181476e-07       -2.410683    0.016439\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}