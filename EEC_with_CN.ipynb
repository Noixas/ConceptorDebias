{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEC with CN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/master/EEC_with_CN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WQJS8yEwygVb",
        "colab_type": "code",
        "outputId": "2b62b81b-6d92-4ad1-bcc8-fdc1b4ba9a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:48:55--  http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip\n",
            "Resolving www.saifmohammad.com (www.saifmohammad.com)... 192.185.17.122\n",
            "Connecting to www.saifmohammad.com (www.saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102568 (100K) [application/zip]\n",
            "Saving to: ‘Equity-Evaluation-Corpus.zip’\n",
            "\n",
            "Equity-Evaluation-C 100%[===================>] 100.16K   573KB/s    in 0.2s    \n",
            "\n",
            "2019-02-28 13:48:55 (573 KB/s) - ‘Equity-Evaluation-Corpus.zip’ saved [102568/102568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Le67qqg0ypdn",
        "colab_type": "code",
        "outputId": "c1f81506-a51f-42c2-fb56-fce969076971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Equity-Evaluation-Corpus.zip\n",
            "  inflating: Equity-Evaluation-Corpus.csv  \n",
            "  inflating: README.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdMrdkW5ypSC",
        "colab_type": "code",
        "outputId": "4efa5e30-8555-4ea4-e0e7-d3058706e8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "07NMbgS0y5ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EEC = pd.read_csv('/content/Equity-Evaluation-Corpus.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHGlOXkfzHYL",
        "colab_type": "code",
        "outputId": "523ef208-819c-4723-c9ab-2dd62795a722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "EEC[0:5]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Template</th>\n",
              "      <th>Person</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Race</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Emotion word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-En-mystery-05498</td>\n",
              "      <td>Alonzo feels angry.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-En-mystery-11722</td>\n",
              "      <td>Alonzo feels furious.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>furious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-En-mystery-11364</td>\n",
              "      <td>Alonzo feels irritated.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>irritated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-En-mystery-14320</td>\n",
              "      <td>Alonzo feels enraged.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>enraged</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-En-mystery-14114</td>\n",
              "      <td>Alonzo feels annoyed.</td>\n",
              "      <td>&lt;person subject&gt; feels &lt;emotion word&gt;.</td>\n",
              "      <td>Alonzo</td>\n",
              "      <td>male</td>\n",
              "      <td>African-American</td>\n",
              "      <td>anger</td>\n",
              "      <td>annoyed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      ID                 Sentence  \\\n",
              "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
              "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
              "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
              "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
              "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
              "\n",
              "                                 Template  Person Gender              Race  \\\n",
              "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
              "\n",
              "  Emotion Emotion word  \n",
              "0   anger        angry  \n",
              "1   anger      furious  \n",
              "2   anger    irritated  \n",
              "3   anger      enraged  \n",
              "4   anger      annoyed  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "7PipGcPqDAsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "EaIytYquTinV",
        "colab_type": "code",
        "outputId": "028bda41-eac1-4ab6-e3b6-5989313e6b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:47, 56.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iERp98e_DE0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Word2vec embeddings\n",
        "CN performed better using word2vec embeddings. For all 4 sentiments, CN showed improvements on debiasing gender bias.\n",
        "If using GloVe embeddings, CN showed improvements on anger, fear and joy. For the sentiment 'sadness', CN gave a higher gender difference. However, by my observations, results can be improved if using more female and male names to find conceptors. So with a larger name datasets, the results of 'sadness' may also show improvements on debiasing."
      ]
    },
    {
      "metadata": {
        "id": "89VbGhaRywxU",
        "colab_type": "code",
        "outputId": "0af4163a-cc39-4699-d4ca-7467c0dd4e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:37, 44.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilnFmeJ22HSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk0C_cga8FVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load fasttext"
      ]
    },
    {
      "metadata": {
        "id": "PvnD-qf98HIT",
        "colab_type": "code",
        "outputId": "c59d7a6a-134f-4b07-e6df-e769280a435a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Zl6a75Ybf8do9uupmrJWKQMnvqqme4fh\n",
            "To: /content/fasttext.bin\n",
            "2.42GB [00:36, 66.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VdnZkDWH8cqU",
        "colab_type": "code",
        "outputId": "2c62594b-9a8a-450b-b02b-fa08f17a9768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "fasttext = KeyedVectors.load_word2vec_format('/content/' + 'fasttext.bin', binary=True)\n",
        "print('The fasttext embedding has been loaded!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fasttext embedding has been loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s7NSiKG2DN2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load male and female name lists\n"
      ]
    },
    {
      "metadata": {
        "id": "cIyTozuW3V2H",
        "colab_type": "code",
        "outputId": "ea9e151d-5d65-45e3-c8ef-199c8fe83c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:59:10--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20466 (20K) [text/plain]\n",
            "Saving to: ‘male.txt’\n",
            "\n",
            "male.txt            100%[===================>]  19.99K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-02-28 13:59:10 (267 KB/s) - ‘male.txt’ saved [20466/20466]\n",
            "\n",
            "--2019-02-28 13:59:11--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35751 (35K) [text/plain]\n",
            "Saving to: ‘female.txt’\n",
            "\n",
            "female.txt          100%[===================>]  34.91K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-02-28 13:59:11 (472 KB/s) - ‘female.txt’ saved [35751/35751]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Du8iVH8ZBApb",
        "colab_type": "code",
        "outputId": "e5f62d68-8c1a-4d66-dcce-09a7b34b9d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:59:15--  https://gist.githubusercontent.com/mbejda/61eb488cec271086632d/raw/6340b8045b28c2abc0b1d44cfbc80f40284ef890/Black-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 921600 (900K) [text/plain]\n",
            "Saving to: ‘Black-Male-Names.csv’\n",
            "\n",
            "\rBlack-Male-Names.cs   0%[                    ]       0  --.-KB/s               \rBlack-Male-Names.cs 100%[===================>] 900.00K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-02-28 13:59:15 (20.3 MB/s) - ‘Black-Male-Names.csv’ saved [921600/921600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XkgU1s9uBFzD",
        "colab_type": "code",
        "outputId": "cca7dadf-9969-49fd-906b-e36846666548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:59:17--  https://gist.githubusercontent.com/mbejda/6c2293ba3333b7e76269/raw/60aa0c95e8ee9b11b915a26f47480fef5c3203ed/White-Male-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1149042 (1.1M) [text/plain]\n",
            "Saving to: ‘White-Male-Names.csv’\n",
            "\n",
            "\rWhite-Male-Names.cs   0%[                    ]       0  --.-KB/s               \rWhite-Male-Names.cs 100%[===================>]   1.10M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-02-28 13:59:17 (24.9 MB/s) - ‘White-Male-Names.csv’ saved [1149042/1149042]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aMwQpmkxEWBv",
        "colab_type": "code",
        "outputId": "27e1e022-fe3d-41e8-f9a1-4838a45cb831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:59:20--  https://gist.githubusercontent.com/mbejda/26ad0574eda7fca78573/raw/6936d1a8f5fa5220f2f60a51a06a35b172c50f93/White-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121903 (119K) [text/plain]\n",
            "Saving to: ‘White-Female-Names.csv’\n",
            "\n",
            "\rWhite-Female-Names.   0%[                    ]       0  --.-KB/s               \rWhite-Female-Names. 100%[===================>] 119.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-02-28 13:59:20 (5.48 MB/s) - ‘White-Female-Names.csv’ saved [121903/121903]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zlhooFTdEXIC",
        "colab_type": "code",
        "outputId": "5aad2ee2-f680-49e4-dccb-4ccaea31b373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-28 13:59:22--  https://gist.githubusercontent.com/mbejda/9dc89056005a689a6456/raw/bb6ef2375f1289d0ef10dbd8e9469670ac23ceab/Black-Female-Names.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64757 (63K) [text/plain]\n",
            "Saving to: ‘Black-Female-Names.csv’\n",
            "\n",
            "\rBlack-Female-Names.   0%[                    ]       0  --.-KB/s               \rBlack-Female-Names. 100%[===================>]  63.24K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-02-28 13:59:22 (4.25 MB/s) - ‘Black-Female-Names.csv’ saved [64757/64757]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LC3JKbM1Xmkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glove = KeyedVectors.load_word2vec_format('/content/' + 'gensim_glove.840B.300d.txt.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeCv7ip13uN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/' + 'GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXx6x2vGEshx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get frequency list (used in calculating sentence embeddings)"
      ]
    },
    {
      "metadata": {
        "id": "MWwGFIWGXqU7",
        "colab_type": "code",
        "outputId": "493436ce-9352-48d4-f1f7-856c6e0b3d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SIF'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 2.80 MiB | 18.85 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRf-8VO3X0y7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wikiWordsPath = '/content' + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZi3h1qOBSap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load white/black names"
      ]
    },
    {
      "metadata": {
        "id": "dpuRepkwM0Ma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-V9S_T5FBXLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "f = open('/content/White-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BjMZUac-B4ga",
        "colab_type": "code",
        "outputId": "b843ff83-7cb9-4f33-b872-8bf9ff4d4bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "Joae0NAZCVbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/Black-Male-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrNPXn6YCcbM",
        "colab_type": "code",
        "outputId": "85f38f67-ca33-42bd-e3ef-260391fd5477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "IKdc4FQcE4s3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/White-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrJhXzkPFbgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/Black-Female-Names.csv', 'r+')\n",
        "f.readline()\n",
        "for line in f:\n",
        "  word_list.append(line.rstrip().split(',')[1].split(' ')[1])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vA6OIHCFgeI",
        "colab_type": "code",
        "outputId": "caa24f07-40f0-46c9-8fe8-f6e457b72f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "TWXuqqFmE1_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load gender names"
      ]
    },
    {
      "metadata": {
        "id": "Rog_F2625pyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/male.txt', 'r+')\n",
        "i = 0\n",
        "word_list= []\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D75vc0Q86cIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/female.txt', 'r+')\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1pLLoV-6gSv",
        "colab_type": "code",
        "outputId": "a254dadf-fec7-40d1-a6e0-6ffcaf0c70bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "aVKauBMi6gJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open('/content/name.txt', 'r+')\n",
        "#word_list = []\n",
        "for line in f:\n",
        "  for item in line.rstrip().split(' '):\n",
        "    word_list.append(item)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "shXdpgjByXkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0dFRyTKXc4WR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Racial Names"
      ]
    },
    {
      "metadata": {
        "id": "y4p870_Oc7hC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These are names in the paper\n",
        "word_list = ['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance',\n",
        "       'Darnell', 'Lamar', 'Malik', 'Terrence', 'Adam', 'Harry', 'Josh',\n",
        "       'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack','Nichelle',\n",
        "       'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha',\n",
        "       'Tia', 'Lakisha', 'Latoya', 'Amanda', 'Courtney', 'Heather',\n",
        "       'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie',\n",
        "       'Ellen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7Q_CBQ6dkUs",
        "colab_type": "code",
        "outputId": "7d14b76e-3bc2-49b6-b4bf-77615446cfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "EEC['Person'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Alonzo', 'Jamel', 'Alphonse', 'Jerome', 'Leroy', 'Torrance',\n",
              "       'Darnell', 'Lamar', 'Malik', 'Terrence', 'Adam', 'Harry', 'Josh',\n",
              "       'Roger', 'Alan', 'Frank', 'Justin', 'Ryan', 'Andrew', 'Jack', 'he',\n",
              "       'this man', 'this boy', 'my brother', 'my son', 'my husband',\n",
              "       'my boyfriend', 'my father', 'my uncle', 'my dad', 'Nichelle',\n",
              "       'Shereen', 'Ebony', 'Latisha', 'Shaniqua', 'Jasmine', 'Tanisha',\n",
              "       'Tia', 'Lakisha', 'Latoya', 'Amanda', 'Courtney', 'Heather',\n",
              "       'Melanie', 'Katie', 'Betsy', 'Kristin', 'Nancy', 'Stephanie',\n",
              "       'Ellen', 'she', 'this woman', 'this girl', 'my sister',\n",
              "       'my daughter', 'my wife', 'my girlfriend', 'my mother', 'my aunt',\n",
              "       'my mom', 'him', 'her'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "HjvwEWHd6wmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNW92mNQ_B_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For word2vec data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JXi_dnD7EkN",
        "colab_type": "code",
        "outputId": "76763cc8-7733-4d58-84dd-0012c1b29207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7099, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "-wU25Uq1vdUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Sentence embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iZFRcuzwmZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Sentence:\n",
        "    \n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itl-QRYavh9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_sif_benchmark(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "#    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "#    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6KBvMZJGRGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "def run_conceptor_benchmark(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =2): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        " #   sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        " #   sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0) \n",
        " #   print(sen_embeddings)\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtceGUSqxVPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "#  p_raw.append([p1.statistic, p2.pvalue])\n",
        "#  print('race difference on Raw and CN data:')\n",
        "#  print(abs((sum(aa)-sum(ea))/len(aa)), abs((sum(aa_cn)-sum(ea_cn))/len(aa_cn)))\n",
        "#  print('t value and p value :')\n",
        "#  print(p1,p2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WRYwT1Odl0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b28dfef9-1db9-4fa1-88a3-8b3297bb7402"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "#p['sentiment'] = ['anger','fear','joy','sadness']\n",
        "#p.reset_index('sentiment')\n",
        "print(p)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          19.359635  3.104938e-57       16.952476  1.884045e-47\n",
            "fear           21.366772  2.309479e-65       20.151225  1.896418e-60\n",
            "joy            11.707836  6.245311e-27       10.351089  4.471070e-22\n",
            "sadness        17.006111  1.142249e-47       16.881343  3.657869e-47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CHbCeLXbQcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1609e0b4-3078-45dd-948c-5ae195376529"
      },
      "cell_type": "code",
      "source": [
        "p1.pvalue, p1.statistic"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1422485946061406e-47, 17.006110741058613)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "nqBE6INvU93r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZGbZvUlgE3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "2f12d0e9-dac1-4ee5-b04d-07165434d207"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          13.849456  4.572745e-35        5.564122  5.255272e-08\n",
            "fear            8.261900  3.016258e-15       -2.214267  2.745619e-02\n",
            "joy             5.400960  1.228679e-07        1.979456  4.855011e-02\n",
            "sadness        19.543729  5.545095e-58       15.293601  9.001127e-41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RumpnNDpq57m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PavqP7YWCsHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bG2OFpyHgOdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d5dfc76f-6e4e-4180-b0f6-41bd524167b3"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -39.229215  5.467233e-130      -28.314121   1.967884e-92\n",
            "fear          -53.682502  1.007069e-170      -45.070483  1.457789e-147\n",
            "joy           -36.353356  1.032966e-120      -33.692194  9.716276e-112\n",
            "sadness       -22.533354   4.817098e-70      -26.089576   5.333202e-84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifykhtkiVCic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PHkyqqWgZhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9498a268-db22-440d-9470-11cb49a5a34a"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger         -25.594525   4.332972e-82      -18.320194  5.245264e-53\n",
            "fear          -33.008122  2.269988e-109      -25.057505  5.264661e-80\n",
            "joy           -29.708214   1.378851e-97      -21.810645  3.782584e-67\n",
            "sadness       -15.018152   1.128162e-39      -14.605255  4.903266e-38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04hAVdzO80en",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLYZ68Q6vXwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='male')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y62itx1kghUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c0e5bd30-07d9-4ca0-952e-bb3bfcd4af7f"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -24.943738   1.461045e-79      -18.225032   1.278958e-52\n",
            "fear          -38.831695  9.875491e-129      -33.469088  5.717150e-111\n",
            "joy           -23.820355   3.732282e-75      -22.105511   2.481160e-68\n",
            "sadness       -19.571735   4.267023e-58      -15.474926   1.695819e-41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-xV8OlU9UacY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') & (sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European') & (sent_sent['Gender']=='female')]\n",
        "  #print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZA8Bf0ignW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "5aec4707-1102-4c43-d8d9-4edaaedc683c"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger           9.036385  1.130757e-17        3.902433  1.142794e-04\n",
            "fear            3.073295  2.283697e-03       -4.647903  4.761504e-06\n",
            "joy           -16.240469  1.423592e-44       -7.902355  3.615591e-14\n",
            "sadness         4.786356  2.512300e-06       -0.268713  7.883090e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFapDcejVntk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using averaged sentiment embeddings"
      ]
    },
    {
      "metadata": {
        "id": "kRYsz7qiV-Ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_sif_benchmark(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    #average sentiment embedding based on several emotional words of the same sentiment\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis=0)    \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOJbKd2kVwc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "def run_conceptor_benchmark(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha =2): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    sen_list = EEC[EEC['Emotion']==sen]['Emotion word'].unique()\n",
        "    sen_embeddings = np.average([model[item] for item in sen_list if item in model.vocab], axis = 0) \n",
        " #   print(sen_embeddings)\n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-2) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    proj1 = embedding1.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    proj2 = embedding2.dot(sen_embeddings)/norm(sen_embeddings)\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFkCnIDDWdgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gutvU6j4V4LH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXODIeHEgzZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0006f795-8a8e-4584-a520-276cba215bfe"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger          18.876432  2.863949e-55       10.708958  2.497658e-23\n",
            "fear           18.281446  7.540234e-53        9.122867  5.946521e-18\n",
            "joy            14.240858  1.340659e-36        7.094972  7.256353e-12\n",
            "sadness        15.365000  4.667011e-41        9.472993  4.250451e-19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EzflVRUWksZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyqNSdmqg6Uz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "377b1cf3-0f08-4bdc-b9df-7c1c879d283f"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger           6.118688  2.533850e-09        0.521135    0.602603\n",
            "fear            4.115710  4.820979e-05       -1.813532    0.070609\n",
            "joy             1.940412  5.313473e-02       -0.211603    0.832540\n",
            "sadness         2.070742  3.911770e-02       -1.184341    0.237084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X-idjANoWlWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUewIufVWq6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p = []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGeEh_QHhCOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "cfae4822-a46b-4ff6-8626-1334dfa12afb"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -33.357260  1.393124e-110      -39.290941  3.494110e-130\n",
            "fear          -41.600778  2.538149e-137      -43.037422  1.246651e-141\n",
            "joy           -48.753785  7.681814e-158      -40.894821  3.616948e-135\n",
            "sadness       -40.561857  3.825451e-134      -40.225661  4.193128e-133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljmJ9ZbDWrWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p= []\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'glove', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhhJCudrhPnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "93fa8278-0bc4-45b4-817e-73d1ae8e16b9"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic    cn_p_value\n",
            "anger         -24.210266   1.087004e-76      -24.209658  1.092996e-76\n",
            "fear          -33.929640  1.483594e-112      -29.540503  5.677200e-97\n",
            "joy           -30.262349   1.316721e-99      -27.768400  2.185446e-90\n",
            "sadness       -33.264375  2.922746e-110      -26.979861  2.099917e-87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PJ3AHZS3WzIb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For Fasttext data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([fasttext[word] for word in word_list if word in fasttext.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EEFY9sylWzfw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p =[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='male')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='male') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vg5V6nAzhZKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7a613339-bcc9-495f-e944-f8a07cd8db70"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic    raw_p_value  cn_t_statistic     cn_p_value\n",
            "anger         -46.225740  7.524439e-151      -42.788945  6.822388e-141\n",
            "fear          -40.925205  2.918379e-135      -37.277705  9.673073e-124\n",
            "joy           -43.957295  2.444131e-144      -36.843588  2.525190e-122\n",
            "sadness       -44.227992  3.970227e-145      -34.961843  4.557815e-116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADoqYIRFW3iY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p=[]\n",
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  aa = []\n",
        "  ea = []\n",
        "  aa_cn = []\n",
        "  ea_cn = []\n",
        "  sent_sent = []\n",
        "  sent_aa = []\n",
        "  sent_ea = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_aa = sent_sent[(sent_sent['Race']=='African-American') &(sent_sent['Gender']=='female')]\n",
        "  sent_ea = sent_sent[(sent_sent['Race']=='European')&(sent_sent['Gender']=='female') ]\n",
        " # print(len(sent_ea))\n",
        "  for sen1, sen2 in zip(sent_aa['Sentence'], sent_ea['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'fasttext', frequencies, 0.0001)\n",
        "    aa.append(score1)\n",
        "    ea.append(score2)\n",
        "    aa_cn.append(score3)\n",
        "    ea_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(aa, ea)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(aa_cn, ea_cn)\n",
        "  p.append([p1.statistic, p1.pvalue, p2.statistic, p2.pvalue])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJwF08B1hfmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e80df4ee-0961-4833-ae74-bbcdd1f289b8"
      },
      "cell_type": "code",
      "source": [
        "print('RAW vs CN data using WORD2VEC, male')\n",
        "p = pd.DataFrame(p, index=['anger','fear','joy','sadness'], columns= ['raw_t_statistic', 'raw_p_value', 'cn_t_statistic', 'cn_p_value'])\n",
        "print(p)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAW vs CN data using WORD2VEC, male\n",
            "         raw_t_statistic   raw_p_value  cn_t_statistic  cn_p_value\n",
            "anger          12.255394  5.795978e-29        1.919071    0.055791\n",
            "fear            7.172205  4.445886e-12       -3.024353    0.002676\n",
            "joy            -0.056098  9.552957e-01       -3.667741    0.000283\n",
            "sadness         5.408571  1.181476e-07       -3.532512    0.000467\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}